{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import numpy.linalg as lia\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBGRImage(path):\n",
    "    image = BGR(cv.imread(path))\n",
    "    return image\n",
    "\n",
    "def loadGreyImage(path):\n",
    "    image = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "    return image\n",
    "\n",
    "def BGR(image):\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def displayGreyImage(image, imageName):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "\n",
    "def displayGreyWindows(image, imageName):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "    \n",
    "def displayBGRImage(image, imageName, size):\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(image)\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "    \n",
    "def displayBGRImageLarge(image, imageName):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    plt.imshow(image)\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "    \n",
    "def imageSideBySide(images, imageNames,size):\n",
    "    row = np.ceil(len(images)/20)\n",
    "    fig=plt.figure(figsize=(size, size/2))\n",
    "    for i, image in enumerate(images):\n",
    "        fig.add_subplot(row, 20, i+1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(imageNames[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_dataset', 'train_dataset', 'train_labels']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 25, 26\n",
    "size = 14, 12\n",
    "\n",
    "f = h5py.File('MNIST_synthetic.h5', 'r')\n",
    "\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.squeeze(np.array(f[\"train_dataset\"])).copy()\n",
    "train_labels = np.squeeze(np.array(f[\"train_labels\"])).copy()\n",
    "test_dataset = np.squeeze(np.array(f[\"test_dataset\"])).copy()\n",
    "\n",
    "singulars_digits = []\n",
    "singulars_labels = []\n",
    "\n",
    "doubles_digits = []\n",
    "doubles_labels = []\n",
    "\n",
    "triples_digits = []\n",
    "triples_labels = []\n",
    "\n",
    "quadruples_digits = []\n",
    "quadruples_labels = []\n",
    "\n",
    "quintuples_digits = []\n",
    "quintuples_labels = []\n",
    "\n",
    "\n",
    "for i, labels in enumerate(train_labels):\n",
    "    if labels[1] == 10:\n",
    "        singulars_digits.append(train_dataset[i])\n",
    "        singulars_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[1] != 10 and labels[2] == 10:\n",
    "        doubles_digits.append(train_dataset[i])\n",
    "        doubles_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[2] != 10 and labels[3] == 10:\n",
    "        triples_digits.append(train_dataset[i])\n",
    "        triples_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[3] != 10 and labels[4] == 10:\n",
    "        quadruples_digits.append(train_dataset[i])\n",
    "        quadruples_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[4] != 10:\n",
    "        quintuples_digits.append(train_dataset[i])\n",
    "        quintuples_labels.append(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "singulars_digits = np.array(singulars_digits)     \n",
    "doubles_digits = np.array(doubles_digits)  \n",
    "triples_digits = np.array(triples_digits)    \n",
    "quadruples_digits = np.array(quadruples_digits)    \n",
    "quintuples_digits = np.array(quintuples_digits)    \n",
    "\n",
    "singulars_labels = np.array(singulars_labels).T[0]\n",
    "doubles_labels = np.array(doubles_labels).T[0:2].T\n",
    "triples_label = np.array(triples_labels).T[0:3].T\n",
    "quadruples_label = np.array(quadruples_labels).T[0:4].T\n",
    "quintuples_label = np.array(quintuples_labels).T[0:5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_singulars_dataset = []\n",
    "final_singulars_labels = list(singulars_labels)\n",
    "for i, digit in enumerate(singulars_digits):\n",
    "    final_singulars_dataset.append(digit[26:38,26:38])\n",
    "    \n",
    "final_doubles_dataset = []\n",
    "final_doubles_labels = []\n",
    "for i, digit in enumerate(doubles_digits):\n",
    "    final_doubles_dataset.append(digit[26:38,20:32])\n",
    "    final_doubles_dataset.append(digit[26:38,32:44])\n",
    "    final_doubles_labels.append(doubles_labels[i][0])\n",
    "    final_doubles_labels.append(doubles_labels[i][1])\n",
    "\n",
    "final_triples_dataset = []\n",
    "final_triples_labels = []\n",
    "for i, digit in enumerate(triples_digits):\n",
    "    final_triples_dataset.append(digit[26:38,14:26])\n",
    "    final_triples_dataset.append(digit[26:38,26:38])\n",
    "    final_triples_dataset.append(digit[26:38,38:50])\n",
    "    final_triples_labels.append(triples_labels[i][0])\n",
    "    final_triples_labels.append(triples_labels[i][1])\n",
    "    final_triples_labels.append(triples_labels[i][2])\n",
    "    \n",
    "final_quadruples_dataset = []\n",
    "final_quadruples_labels = []\n",
    "for i, digit in enumerate(quadruples_digits):\n",
    "    final_quadruples_dataset.append(digit[26:38,8:20])\n",
    "    final_quadruples_dataset.append(digit[26:38,20:32])\n",
    "    final_quadruples_dataset.append(digit[26:38,32:44])\n",
    "    final_quadruples_dataset.append(digit[26:38,44:56])\n",
    "    final_quadruples_labels.append(quadruples_labels[i][0])\n",
    "    final_quadruples_labels.append(quadruples_labels[i][1])    \n",
    "    final_quadruples_labels.append(quadruples_labels[i][2])\n",
    "    final_quadruples_labels.append(quadruples_labels[i][3]) \n",
    "    \n",
    "final_quintuples_dataset = []\n",
    "final_quintuples_labels = []\n",
    "for i, digit in enumerate(quintuples_digits):\n",
    "    final_quintuples_dataset.append(digit[26:38,2:14])\n",
    "    final_quintuples_dataset.append(digit[26:38,14:26])\n",
    "    final_quintuples_dataset.append(digit[26:38,26:38])\n",
    "    final_quintuples_dataset.append(digit[26:38,38:50])\n",
    "    final_quintuples_dataset.append(digit[26:38,50:62])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][0])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][1])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][2])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][3])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = final_singulars_dataset + final_doubles_dataset + final_triples_dataset + final_quadruples_dataset + final_quintuples_dataset\n",
    "merged_labels = final_singulars_labels + final_doubles_labels + final_triples_labels + final_quadruples_labels + final_quintuples_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of 0's in train dataset: 16379\n",
      "number of 1's in train dataset: 18819\n",
      "number of 2's in train dataset: 17095\n",
      "number of 3's in train dataset: 17220\n",
      "number of 4's in train dataset: 16393\n",
      "number of 5's in train dataset: 15275\n",
      "number of 6's in train dataset: 16401\n",
      "number of 7's in train dataset: 17611\n",
      "number of 8's in train dataset: 16175\n",
      "number of 9's in train dataset: 16518\n",
      "total number of digits in train dataset: 167886\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for digit in range(10):\n",
    "    digit_count = list(merged_labels).count(digit)\n",
    "    print(f\"number of {digit}'s in train dataset: {digit_count}\")\n",
    "    count += digit_count\n",
    "\n",
    "print(\"total number of digits in train dataset:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitsTrainingSetSize = int(np.ceil(0.8 * len(merged_dataset)))\n",
    "digitsValidationSetSize = int(len(merged_labels) - digitsTrainingSetSize)\n",
    "\n",
    "xValidationSet = []\n",
    "yValidationSet = []\n",
    "\n",
    "for index, digit in enumerate(merged_dataset[0:digitsValidationSetSize]):\n",
    "    xValidationSet.append(digit)\n",
    "    yValidationSet.append(merged_labels[index])\n",
    "\n",
    "xTrainingSet = []\n",
    "yTrainingSet = []\n",
    "\n",
    "start = len(xValidationSet)\n",
    "\n",
    "for i, digit in enumerate(merged_dataset[start:]):\n",
    "    xTrainingSet.append(digit)\n",
    "    yTrainingSet.append(merged_labels[i+start])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding all digits in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_digits(train_dataset, size):\n",
    "    thresh_train_dataset = train_dataset.copy()\n",
    "    thresh_train_dataset[thresh_train_dataset>30] = 255\n",
    "    thresh_train_dataset[thresh_train_dataset!=255] = 0\n",
    "    i,j = np.where(thresh_train_dataset[:,:]!=0)\n",
    "    #print(i)\n",
    "    bottom_bound = np.min(i)\n",
    "    top_bound = np.max(i)\n",
    "    left_bound = np.min(j)\n",
    "    right_bound = np.max(j)\n",
    "    #print(top_bound, bottom_bound)\n",
    "\n",
    "    h = top_bound-bottom_bound\n",
    "    w = right_bound-left_bound\n",
    "\n",
    "    bounded_train_dataset = train_dataset[bottom_bound-1:top_bound+2,left_bound-1:right_bound+2]\n",
    "    thresh = bounded_train_dataset.copy()\n",
    "    thresh[thresh>30] = 255\n",
    "    thresh[thresh!=255] = 0\n",
    "    #ret, thresh = cv2.threshold(bounded_train_dataset, 30, 255, 0)\n",
    "    #seg = np.where(np.any(thresh, axis=0)==0)\n",
    "    seg = np.where(np.any(thresh, axis=0)==0)\n",
    "\n",
    "    #print(seg)\n",
    "    seg_list = np.asarray(seg)\n",
    "    seg_list = seg_list[0]\n",
    "    #print(seg_list)\n",
    "    from statistics import stdev\n",
    "\n",
    "    if len(seg_list)>2:\n",
    "        # create a list of the gaps between the consecutive values\n",
    "        gaps = [y - x for x, y in zip(seg_list[:-1], seg_list[1:])]\n",
    "        # have python calculate the standard deviation for the gaps\n",
    "        sd = stdev(gaps)\n",
    "\n",
    "        # create a list of lists, put the first value of the source data in the first\n",
    "        lists = [[seg_list[0]]]\n",
    "        for x in seg_list[1:]:\n",
    "            # if the gap from the current item to the previous is more than 1 SD\n",
    "            # Note: the previous item is the last item in the last list\n",
    "            # Note: the '> 1' is the part you'd modify to make it stricter or more relaxed\n",
    "            if (x - lists[-1][-1]) / (sd+1e-18) > 0.8:\n",
    "                # then start a new list\n",
    "                lists.append([])\n",
    "            # add the current item to the last list in the list\n",
    "            lists[-1].append(x)\n",
    "\n",
    "        splits = np.asarray([np.ceil(np.mean(lists[i])) for i in range(len(lists))]).astype(int)\n",
    "\n",
    "    else:\n",
    "        splits = np.asarray(seg_list)\n",
    "    #print(splits)\n",
    "\n",
    "    n_digits = len(splits)-1\n",
    "    #digits = np.zeros(n_digits, )\n",
    "    digits = []\n",
    "    for i in range(n_digits):\n",
    "        temp = bounded_train_dataset[:,splits[i]:splits[i+1]]\n",
    "        # if temp is less than recommeded size first pad on left and then on both sides\n",
    "        temp_padded = temp.copy()\n",
    "        if (temp.shape[0] != size) or  (temp.shape[1] != size):\n",
    "            diff_y = size-temp.shape[0]\n",
    "            split_diff_y = diff_y//2\n",
    "            remainder_diff_y = diff_y%2\n",
    "            diff_x = size-temp.shape[1]\n",
    "            split_diff_x = diff_x//2\n",
    "            remainder_diff_x = diff_x%2\n",
    "#             print(diff_y)\n",
    "#             print(split_diff_y)\n",
    "            temp_padded = np.pad(temp, ((split_diff_y+remainder_diff_y,split_diff_y),(split_diff_x+remainder_diff_x,split_diff_x)))\n",
    "\n",
    "        digits.append(temp_padded)\n",
    "    return digits, n_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect at index: 367\n",
      "incorrect at index: 1351\n",
      "incorrect at index: 1606\n",
      "incorrect at index: 2684\n",
      "incorrect at index: 3172\n",
      "incorrect at index: 3771\n",
      "incorrect at index: 3838\n",
      "incorrect at index: 3883\n",
      "incorrect at index: 4011\n",
      "incorrect at index: 4447\n",
      "incorrect at index: 4639\n",
      "incorrect at index: 4747\n",
      "incorrect at index: 5419\n",
      "incorrect at index: 5442\n",
      "incorrect at index: 5772\n",
      "incorrect at index: 5930\n",
      "incorrect at index: 7118\n",
      "incorrect at index: 7981\n",
      "incorrect at index: 8652\n",
      "incorrect at index: 8860\n",
      "incorrect at index: 8941\n",
      "incorrect at index: 9038\n",
      "incorrect at index: 9176\n",
      "incorrect at index: 9419\n",
      "incorrect at index: 10702\n",
      "incorrect at index: 11622\n",
      "incorrect at index: 11810\n",
      "incorrect at index: 12806\n",
      "incorrect at index: 13280\n",
      "incorrect at index: 13360\n",
      "incorrect at index: 13514\n",
      "incorrect at index: 14150\n",
      "incorrect at index: 14931\n",
      "incorrect at index: 15844\n",
      "incorrect at index: 16366\n",
      "incorrect at index: 16909\n",
      "incorrect at index: 17030\n",
      "incorrect at index: 17540\n",
      "incorrect at index: 17573\n",
      "incorrect at index: 18122\n",
      "incorrect at index: 18127\n",
      "incorrect at index: 18460\n",
      "incorrect at index: 19104\n",
      "incorrect at index: 19660\n",
      "incorrect at index: 20029\n",
      "incorrect at index: 20764\n",
      "incorrect at index: 21153\n",
      "incorrect at index: 21854\n",
      "incorrect at index: 21980\n",
      "incorrect at index: 22025\n",
      "incorrect at index: 22369\n",
      "incorrect at index: 22596\n",
      "incorrect at index: 23044\n",
      "incorrect at index: 23684\n",
      "incorrect at index: 24026\n",
      "incorrect at index: 24518\n",
      "incorrect at index: 25190\n",
      "incorrect at index: 25233\n",
      "incorrect at index: 25273\n",
      "incorrect at index: 26042\n",
      "incorrect at index: 26094\n",
      "incorrect at index: 26601\n",
      "incorrect at index: 27704\n",
      "incorrect at index: 28516\n",
      "incorrect at index: 28518\n",
      "incorrect at index: 28802\n",
      "incorrect at index: 29359\n",
      "incorrect at index: 29444\n",
      "incorrect at index: 29616\n",
      "incorrect at index: 29775\n",
      "incorrect at index: 30169\n",
      "incorrect at index: 31388\n",
      "incorrect at index: 32154\n",
      "incorrect at index: 32609\n",
      "incorrect at index: 33049\n",
      "incorrect at index: 33071\n",
      "incorrect at index: 33204\n",
      "incorrect at index: 33908\n",
      "incorrect at index: 34014\n",
      "incorrect at index: 34814\n",
      "incorrect at index: 34852\n",
      "incorrect at index: 34877\n",
      "incorrect at index: 35542\n",
      "incorrect at index: 36288\n",
      "incorrect at index: 36777\n",
      "incorrect at index: 37607\n",
      "incorrect at index: 37788\n",
      "incorrect at index: 37869\n",
      "incorrect at index: 37986\n",
      "incorrect at index: 39113\n",
      "incorrect at index: 39226\n",
      "incorrect at index: 39274\n",
      "incorrect at index: 39648\n",
      "incorrect at index: 39758\n",
      "incorrect at index: 39896\n",
      "incorrect at index: 40225\n",
      "incorrect at index: 40457\n",
      "incorrect at index: 41329\n",
      "incorrect at index: 41954\n",
      "incorrect at index: 42009\n",
      "incorrect at index: 42555\n",
      "incorrect at index: 42678\n",
      "incorrect at index: 44367\n",
      "incorrect at index: 44518\n",
      "incorrect at index: 44650\n",
      "incorrect at index: 45004\n",
      "incorrect at index: 45382\n",
      "incorrect at index: 46543\n",
      "incorrect at index: 46663\n",
      "incorrect at index: 46759\n",
      "incorrect at index: 46979\n",
      "incorrect at index: 47846\n",
      "incorrect at index: 47884\n",
      "incorrect at index: 48964\n",
      "incorrect at index: 49315\n",
      "incorrect at index: 49406\n",
      "incorrect at index: 50272\n",
      "incorrect at index: 50383\n",
      "incorrect at index: 50715\n",
      "incorrect at index: 50729\n",
      "incorrect at index: 51103\n",
      "incorrect at index: 51106\n",
      "incorrect at index: 52290\n",
      "incorrect at index: 52762\n",
      "incorrect at index: 53061\n",
      "incorrect at index: 54031\n",
      "incorrect at index: 54206\n",
      "incorrect at index: 54314\n",
      "incorrect at index: 54356\n",
      "incorrect at index: 54528\n",
      "incorrect at index: 55379\n",
      "incorrect at index: 55470\n",
      "incorrect at index: 55693\n",
      "incorrect at index: 55849\n",
      "incorrect at index: 55866\n",
      "total percentage incorrect: 0.24107142857142855 %\n"
     ]
    }
   ],
   "source": [
    "wrong = 0 \n",
    "wrong_arr = []\n",
    "wrong_arr_index = []\n",
    "correct = []\n",
    "\n",
    "for i, sample in enumerate(train_dataset):\n",
    "    snips, n_dig = find_digits(sample, 25)\n",
    "    real_num_digits = 5 - list(train_labels[i]).count(10)\n",
    "\n",
    "    if(n_dig != real_num_digits):\n",
    "        print(\"incorrect at index:\", i)\n",
    "        wrong += 1\n",
    "        wrong_arr.append(snips)\n",
    "        wrong_arr_index.append(i)  \n",
    "\n",
    "print(\"total percentage incorrect:\", wrong / len(train_dataset) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "num_test_digits = 0\n",
    "\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    images, n_digits = find_digits(sample, 25)\n",
    "   \n",
    "    num_test_digits += n_digits\n",
    "\n",
    "divs = []\n",
    "\n",
    "for div in range(1, 100):\n",
    "    if(num_test_digits % (div) == 0):\n",
    "        divs.append(div)\n",
    "\n",
    "batch_size = divs[-1]\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(input_array, label_array, batch_size):\n",
    "    batched = []\n",
    "    label_batched = []\n",
    "    \n",
    "    for i in range(np.floor(len(input_array)/batch_size).astype(int)):\n",
    "        batched.append(np.expand_dims((np.array(input_array[i*batch_size:i*batch_size+batch_size])).astype(np.single),axis=1))\n",
    "        label_batched.append(label_array[i*batch_size:i*batch_size+batch_size])\n",
    "        \n",
    "    return np.array(batched), label_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, h_layers):\n",
    "        self.num_layers = len(h_layers)\n",
    "        self.h_layers = h_layers      \n",
    "        self.convs = []\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        for i, n in enumerate(self.h_layers):\n",
    "            if i == 0:\n",
    "                self.convs.append(nn.Conv2d(1, n, 3))\n",
    "            else:\n",
    "                self.convs.append(nn.Conv2d(self.h_layers[i-1], n, 3))\n",
    "\n",
    "        self.fc1 = nn.Linear(self.h_layers[-1]**2 , 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.h_layers)):\n",
    "            x = F.relu(self.convs[i](x))\n",
    "            \n",
    "        x = x.view(-1, self.h_layers[-1]**2)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN for hyper-parameter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 2420.372\n",
      "[1,    40] loss: 715.456\n",
      "[1,    60] loss: 332.850\n",
      "[1,    80] loss: 314.402\n",
      "[1,   100] loss: 267.440\n",
      "[1,   120] loss: 225.064\n",
      "[1,   140] loss: 255.897\n",
      "[1,   160] loss: 209.045\n",
      "[1,   180] loss: 158.572\n",
      "[1,   200] loss: 136.812\n",
      "[1,   220] loss: 174.208\n",
      "[1,   240] loss: 138.788\n",
      "[1,   260] loss: 185.611\n",
      "[1,   280] loss: 122.219\n",
      "[1,   300] loss: 93.853\n",
      "[1,   320] loss: 115.740\n",
      "[1,   340] loss: 127.626\n",
      "[1,   360] loss: 110.421\n",
      "[1,   380] loss: 77.980\n",
      "[1,   400] loss: 83.712\n",
      "[1,   420] loss: 72.224\n",
      "[1,   440] loss: 84.002\n",
      "[1,   460] loss: 80.047\n",
      "[1,   480] loss: 100.095\n",
      "[1,   500] loss: 67.120\n",
      "[1,   520] loss: 57.032\n",
      "[1,   540] loss: 74.461\n",
      "[1,   560] loss: 79.761\n",
      "[1,   580] loss: 71.433\n",
      "[1,   600] loss: 63.614\n",
      "[1,   620] loss: 65.787\n",
      "[1,   640] loss: 64.685\n",
      "[1,   660] loss: 88.311\n",
      "[1,   680] loss: 77.450\n",
      "[1,   700] loss: 99.435\n",
      "[1,   720] loss: 72.204\n",
      "[1,   740] loss: 63.486\n",
      "[1,   760] loss: 55.889\n",
      "[1,   780] loss: 69.076\n",
      "[1,   800] loss: 43.761\n",
      "[1,   820] loss: 40.038\n",
      "[1,   840] loss: 49.340\n",
      "[1,   860] loss: 49.043\n",
      "[1,   880] loss: 59.252\n",
      "[1,   900] loss: 34.556\n",
      "[1,   920] loss: 48.725\n",
      "[1,   940] loss: 34.651\n",
      "[1,   960] loss: 44.644\n",
      "[1,   980] loss: 61.469\n",
      "[1,  1000] loss: 43.737\n",
      "[1,  1020] loss: 47.054\n",
      "[1,  1040] loss: 41.076\n",
      "[1,  1060] loss: 39.692\n",
      "[1,  1080] loss: 44.842\n",
      "[1,  1100] loss: 47.550\n",
      "[1,  1120] loss: 51.170\n",
      "[1,  1140] loss: 41.329\n",
      "[1,  1160] loss: 30.160\n",
      "[1,  1180] loss: 39.210\n",
      "[1,  1200] loss: 33.570\n",
      "[1,  1220] loss: 39.190\n",
      "[1,  1240] loss: 26.107\n",
      "[1,  1260] loss: 35.055\n",
      "[1,  1280] loss: 39.931\n",
      "[1,  1300] loss: 40.930\n",
      "[1,  1320] loss: 28.519\n",
      "[1,  1340] loss: 23.321\n",
      "[1,  1360] loss: 37.546\n",
      "[1,  1380] loss: 38.994\n",
      "[1,  1400] loss: 31.638\n",
      "[1,  1420] loss: 49.485\n",
      "[1,  1440] loss: 36.014\n",
      "[1,  1460] loss: 32.676\n",
      "[1,  1480] loss: 41.968\n",
      "[1,  1500] loss: 49.279\n",
      "[1,  1520] loss: 34.663\n",
      "[1,  1540] loss: 31.805\n",
      "[1,  1560] loss: 30.594\n",
      "[1,  1580] loss: 33.547\n",
      "[1,  1600] loss: 34.118\n",
      "[1,  1620] loss: 55.897\n",
      "[1,  1640] loss: 59.630\n",
      "[1,  1660] loss: 39.545\n",
      "[1,  1680] loss: 44.894\n",
      "[1,  1700] loss: 36.082\n",
      "[2,    20] loss: 30.323\n",
      "[2,    40] loss: 32.159\n",
      "[2,    60] loss: 26.176\n",
      "[2,    80] loss: 32.435\n",
      "[2,   100] loss: 43.707\n",
      "[2,   120] loss: 23.984\n",
      "[2,   140] loss: 38.622\n",
      "[2,   160] loss: 51.984\n",
      "[2,   180] loss: 37.518\n",
      "[2,   200] loss: 51.643\n",
      "[2,   220] loss: 42.644\n",
      "[2,   240] loss: 35.226\n",
      "[2,   260] loss: 45.270\n",
      "[2,   280] loss: 40.634\n",
      "[2,   300] loss: 29.286\n",
      "[2,   320] loss: 32.612\n",
      "[2,   340] loss: 51.512\n",
      "[2,   360] loss: 38.560\n",
      "[2,   380] loss: 29.056\n",
      "[2,   400] loss: 33.705\n",
      "[2,   420] loss: 21.892\n",
      "[2,   440] loss: 33.786\n",
      "[2,   460] loss: 30.678\n",
      "[2,   480] loss: 36.505\n",
      "[2,   500] loss: 41.310\n",
      "[2,   520] loss: 25.009\n",
      "[2,   540] loss: 45.843\n",
      "[2,   560] loss: 48.229\n",
      "[2,   580] loss: 56.943\n",
      "[2,   600] loss: 38.102\n",
      "[2,   620] loss: 34.627\n",
      "[2,   640] loss: 29.559\n",
      "[2,   660] loss: 33.676\n",
      "[2,   680] loss: 32.824\n",
      "[2,   700] loss: 43.932\n",
      "[2,   720] loss: 31.107\n",
      "[2,   740] loss: 23.220\n",
      "[2,   760] loss: 24.323\n",
      "[2,   780] loss: 18.973\n",
      "[2,   800] loss: 22.677\n",
      "[2,   820] loss: 20.089\n",
      "[2,   840] loss: 24.663\n",
      "[2,   860] loss: 19.176\n",
      "[2,   880] loss: 18.887\n",
      "[2,   900] loss: 22.871\n",
      "[2,   920] loss: 26.125\n",
      "[2,   940] loss: 26.863\n",
      "[2,   960] loss: 23.055\n",
      "[2,   980] loss: 20.478\n",
      "[2,  1000] loss: 23.578\n",
      "[2,  1020] loss: 30.840\n",
      "[2,  1040] loss: 26.298\n",
      "[2,  1060] loss: 23.400\n",
      "[2,  1080] loss: 22.542\n",
      "[2,  1100] loss: 36.600\n",
      "[2,  1120] loss: 26.612\n",
      "[2,  1140] loss: 27.456\n",
      "[2,  1160] loss: 15.792\n",
      "[2,  1180] loss: 27.535\n",
      "[2,  1200] loss: 19.383\n",
      "[2,  1220] loss: 26.855\n",
      "[2,  1240] loss: 19.689\n",
      "[2,  1260] loss: 23.625\n",
      "[2,  1280] loss: 20.374\n",
      "[2,  1300] loss: 20.969\n",
      "[2,  1320] loss: 15.319\n",
      "[2,  1340] loss: 26.516\n",
      "[2,  1360] loss: 33.665\n",
      "[2,  1380] loss: 28.760\n",
      "[2,  1400] loss: 24.343\n",
      "[2,  1420] loss: 28.889\n",
      "[2,  1440] loss: 35.376\n",
      "[2,  1460] loss: 27.824\n",
      "[2,  1480] loss: 42.171\n",
      "[2,  1500] loss: 36.364\n",
      "[2,  1520] loss: 26.704\n",
      "[2,  1540] loss: 27.586\n",
      "[2,  1560] loss: 41.990\n",
      "[2,  1580] loss: 29.853\n",
      "[2,  1600] loss: 32.333\n",
      "[2,  1620] loss: 40.220\n",
      "[2,  1640] loss: 27.844\n",
      "[2,  1660] loss: 19.627\n",
      "[2,  1680] loss: 29.098\n",
      "[2,  1700] loss: 26.335\n",
      "[3,    20] loss: 20.013\n",
      "[3,    40] loss: 28.048\n",
      "[3,    60] loss: 14.916\n",
      "[3,    80] loss: 20.135\n",
      "[3,   100] loss: 33.257\n",
      "[3,   120] loss: 22.498\n",
      "[3,   140] loss: 20.316\n",
      "[3,   160] loss: 31.646\n",
      "[3,   180] loss: 53.807\n",
      "[3,   200] loss: 33.700\n",
      "[3,   220] loss: 28.556\n",
      "[3,   240] loss: 18.889\n",
      "[3,   260] loss: 19.830\n",
      "[3,   280] loss: 25.564\n",
      "[3,   300] loss: 22.103\n",
      "[3,   320] loss: 21.512\n",
      "[3,   340] loss: 22.302\n",
      "[3,   360] loss: 24.935\n",
      "[3,   380] loss: 17.757\n",
      "[3,   400] loss: 26.318\n",
      "[3,   420] loss: 18.570\n",
      "[3,   440] loss: 24.696\n",
      "[3,   460] loss: 20.492\n",
      "[3,   480] loss: 32.408\n",
      "[3,   500] loss: 29.953\n",
      "[3,   520] loss: 18.282\n",
      "[3,   540] loss: 26.427\n",
      "[3,   560] loss: 20.465\n",
      "[3,   580] loss: 26.754\n",
      "[3,   600] loss: 30.725\n",
      "[3,   620] loss: 19.697\n",
      "[3,   640] loss: 18.145\n",
      "[3,   660] loss: 26.706\n",
      "[3,   680] loss: 38.994\n",
      "[3,   700] loss: 33.921\n",
      "[3,   720] loss: 29.644\n",
      "[3,   740] loss: 20.776\n",
      "[3,   760] loss: 10.090\n",
      "[3,   780] loss: 26.314\n",
      "[3,   800] loss: 15.724\n",
      "[3,   820] loss: 15.746\n",
      "[3,   840] loss: 17.678\n",
      "[3,   860] loss: 16.183\n",
      "[3,   880] loss: 18.587\n",
      "[3,   900] loss: 18.233\n",
      "[3,   920] loss: 21.635\n",
      "[3,   940] loss: 12.481\n",
      "[3,   960] loss: 16.116\n",
      "[3,   980] loss: 16.049\n",
      "[3,  1000] loss: 14.084\n",
      "[3,  1020] loss: 20.769\n",
      "[3,  1040] loss: 26.615\n",
      "[3,  1060] loss: 22.199\n",
      "[3,  1080] loss: 14.805\n",
      "[3,  1100] loss: 18.396\n",
      "[3,  1120] loss: 18.348\n",
      "[3,  1140] loss: 15.100\n",
      "[3,  1160] loss: 17.563\n",
      "[3,  1180] loss: 23.328\n",
      "[3,  1200] loss: 16.608\n",
      "[3,  1220] loss: 21.705\n",
      "[3,  1240] loss: 13.049\n",
      "[3,  1260] loss: 26.206\n",
      "[3,  1280] loss: 16.008\n",
      "[3,  1300] loss: 18.386\n",
      "[3,  1320] loss: 21.088\n",
      "[3,  1340] loss: 21.626\n",
      "[3,  1360] loss: 26.838\n",
      "[3,  1380] loss: 18.616\n",
      "[3,  1400] loss: 26.915\n",
      "[3,  1420] loss: 27.235\n",
      "[3,  1440] loss: 27.319\n",
      "[3,  1460] loss: 18.504\n",
      "[3,  1480] loss: 22.798\n",
      "[3,  1500] loss: 33.222\n",
      "[3,  1520] loss: 27.015\n",
      "[3,  1540] loss: 22.846\n",
      "[3,  1560] loss: 28.735\n",
      "[3,  1580] loss: 20.742\n",
      "[3,  1600] loss: 24.088\n",
      "[3,  1620] loss: 27.017\n",
      "[3,  1640] loss: 24.563\n",
      "[3,  1660] loss: 16.701\n",
      "[3,  1680] loss: 20.666\n",
      "[3,  1700] loss: 19.803\n",
      "[4,    20] loss: 23.894\n",
      "[4,    40] loss: 28.636\n",
      "[4,    60] loss: 25.412\n",
      "[4,    80] loss: 26.202\n",
      "[4,   100] loss: 27.419\n",
      "[4,   120] loss: 17.804\n",
      "[4,   140] loss: 22.066\n",
      "[4,   160] loss: 21.297\n",
      "[4,   180] loss: 19.030\n",
      "[4,   200] loss: 8.607\n",
      "[4,   220] loss: 21.971\n",
      "[4,   240] loss: 17.072\n",
      "[4,   260] loss: 16.441\n",
      "[4,   280] loss: 17.085\n",
      "[4,   300] loss: 13.305\n",
      "[4,   320] loss: 18.420\n",
      "[4,   340] loss: 21.373\n",
      "[4,   360] loss: 18.729\n",
      "[4,   380] loss: 15.896\n",
      "[4,   400] loss: 16.265\n",
      "[4,   420] loss: 7.080\n",
      "[4,   440] loss: 22.585\n",
      "[4,   460] loss: 21.958\n",
      "[4,   480] loss: 24.062\n",
      "[4,   500] loss: 25.914\n",
      "[4,   520] loss: 20.916\n",
      "[4,   540] loss: 32.379\n",
      "[4,   560] loss: 19.060\n",
      "[4,   580] loss: 34.787\n",
      "[4,   600] loss: 25.274\n",
      "[4,   620] loss: 13.676\n",
      "[4,   640] loss: 21.877\n",
      "[4,   660] loss: 25.404\n",
      "[4,   680] loss: 14.632\n",
      "[4,   700] loss: 21.210\n",
      "[4,   720] loss: 20.640\n",
      "[4,   740] loss: 23.596\n",
      "[4,   760] loss: 28.586\n",
      "[4,   780] loss: 25.672\n",
      "[4,   800] loss: 18.582\n",
      "[4,   820] loss: 17.799\n",
      "[4,   840] loss: 9.430\n",
      "[4,   860] loss: 15.564\n",
      "[4,   880] loss: 14.751\n",
      "[4,   900] loss: 15.640\n",
      "[4,   920] loss: 20.138\n",
      "[4,   940] loss: 24.300\n",
      "[4,   960] loss: 18.290\n",
      "[4,   980] loss: 11.944\n",
      "[4,  1000] loss: 14.438\n",
      "[4,  1020] loss: 19.256\n",
      "[4,  1040] loss: 14.553\n",
      "[4,  1060] loss: 15.559\n",
      "[4,  1080] loss: 29.975\n",
      "[4,  1100] loss: 21.957\n",
      "[4,  1120] loss: 23.064\n",
      "[4,  1140] loss: 10.915\n",
      "[4,  1160] loss: 18.195\n",
      "[4,  1180] loss: 18.298\n",
      "[4,  1200] loss: 11.084\n",
      "[4,  1220] loss: 14.131\n",
      "[4,  1240] loss: 8.901\n",
      "[4,  1260] loss: 15.532\n",
      "[4,  1280] loss: 19.037\n",
      "[4,  1300] loss: 14.534\n",
      "[4,  1320] loss: 12.336\n",
      "[4,  1340] loss: 6.840\n",
      "[4,  1360] loss: 17.889\n",
      "[4,  1380] loss: 23.371\n",
      "[4,  1400] loss: 21.346\n",
      "[4,  1420] loss: 20.758\n",
      "[4,  1440] loss: 28.758\n",
      "[4,  1460] loss: 22.465\n",
      "[4,  1480] loss: 22.654\n",
      "[4,  1500] loss: 16.784\n",
      "[4,  1520] loss: 24.121\n",
      "[4,  1540] loss: 26.175\n",
      "[4,  1560] loss: 21.455\n",
      "[4,  1580] loss: 10.584\n",
      "[4,  1600] loss: 13.985\n",
      "[4,  1620] loss: 25.788\n",
      "[4,  1640] loss: 25.364\n",
      "[4,  1660] loss: 13.298\n",
      "[4,  1680] loss: 15.885\n",
      "[4,  1700] loss: 12.471\n",
      "[5,    20] loss: 19.864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    40] loss: 32.653\n",
      "[5,    60] loss: 15.715\n",
      "[5,    80] loss: 10.379\n",
      "[5,   100] loss: 27.529\n",
      "[5,   120] loss: 16.553\n",
      "[5,   140] loss: 12.598\n",
      "[5,   160] loss: 19.438\n",
      "[5,   180] loss: 14.584\n",
      "[5,   200] loss: 12.515\n",
      "[5,   220] loss: 12.276\n",
      "[5,   240] loss: 10.310\n",
      "[5,   260] loss: 18.524\n",
      "[5,   280] loss: 23.625\n",
      "[5,   300] loss: 7.049\n",
      "[5,   320] loss: 12.258\n",
      "[5,   340] loss: 18.836\n",
      "[5,   360] loss: 16.409\n",
      "[5,   380] loss: 7.998\n",
      "[5,   400] loss: 18.849\n",
      "[5,   420] loss: 9.272\n",
      "[5,   440] loss: 17.287\n",
      "[5,   460] loss: 21.094\n",
      "[5,   480] loss: 17.876\n",
      "[5,   500] loss: 21.966\n",
      "[5,   520] loss: 19.432\n",
      "[5,   540] loss: 28.471\n",
      "[5,   560] loss: 17.642\n",
      "[5,   580] loss: 20.698\n",
      "[5,   600] loss: 17.954\n",
      "[5,   620] loss: 16.675\n",
      "[5,   640] loss: 15.711\n",
      "[5,   660] loss: 13.846\n",
      "[5,   680] loss: 13.237\n",
      "[5,   700] loss: 19.035\n",
      "[5,   720] loss: 12.518\n",
      "[5,   740] loss: 16.697\n",
      "[5,   760] loss: 12.081\n",
      "[5,   780] loss: 22.084\n",
      "[5,   800] loss: 11.829\n",
      "[5,   820] loss: 20.462\n",
      "[5,   840] loss: 8.229\n",
      "[5,   860] loss: 10.394\n",
      "[5,   880] loss: 7.361\n",
      "[5,   900] loss: 9.971\n",
      "[5,   920] loss: 17.875\n",
      "[5,   940] loss: 16.838\n",
      "[5,   960] loss: 12.728\n",
      "[5,   980] loss: 11.318\n",
      "[5,  1000] loss: 7.898\n",
      "[5,  1020] loss: 13.866\n",
      "[5,  1040] loss: 13.352\n",
      "[5,  1060] loss: 9.996\n",
      "[5,  1080] loss: 15.223\n",
      "[5,  1100] loss: 14.524\n",
      "[5,  1120] loss: 15.581\n",
      "[5,  1140] loss: 8.313\n",
      "[5,  1160] loss: 16.107\n",
      "[5,  1180] loss: 14.109\n",
      "[5,  1200] loss: 9.956\n",
      "[5,  1220] loss: 11.349\n",
      "[5,  1240] loss: 8.317\n",
      "[5,  1260] loss: 12.669\n",
      "[5,  1280] loss: 7.968\n",
      "[5,  1300] loss: 6.579\n",
      "[5,  1320] loss: 9.048\n",
      "[5,  1340] loss: 10.210\n",
      "[5,  1360] loss: 19.795\n",
      "[5,  1380] loss: 14.030\n",
      "[5,  1400] loss: 15.236\n",
      "[5,  1420] loss: 16.828\n",
      "[5,  1440] loss: 17.796\n",
      "[5,  1460] loss: 22.548\n",
      "[5,  1480] loss: 22.108\n",
      "[5,  1500] loss: 16.000\n",
      "[5,  1520] loss: 19.568\n",
      "[5,  1540] loss: 15.467\n",
      "[5,  1560] loss: 16.931\n",
      "[5,  1580] loss: 8.984\n",
      "[5,  1600] loss: 10.616\n",
      "[5,  1620] loss: 31.144\n",
      "[5,  1640] loss: 23.254\n",
      "[5,  1660] loss: 10.142\n",
      "[5,  1680] loss: 13.875\n",
      "[5,  1700] loss: 14.991\n",
      "[6,    20] loss: 20.172\n",
      "[6,    40] loss: 24.725\n",
      "[6,    60] loss: 13.196\n",
      "[6,    80] loss: 9.647\n",
      "[6,   100] loss: 13.322\n",
      "[6,   120] loss: 10.776\n",
      "[6,   140] loss: 12.390\n",
      "[6,   160] loss: 15.082\n",
      "[6,   180] loss: 11.390\n",
      "[6,   200] loss: 10.022\n",
      "[6,   220] loss: 13.786\n",
      "[6,   240] loss: 11.520\n",
      "[6,   260] loss: 17.359\n",
      "[6,   280] loss: 19.923\n",
      "[6,   300] loss: 6.629\n",
      "[6,   320] loss: 24.811\n",
      "[6,   340] loss: 20.377\n",
      "[6,   360] loss: 19.046\n",
      "[6,   380] loss: 7.446\n",
      "[6,   400] loss: 9.881\n",
      "[6,   420] loss: 7.043\n",
      "[6,   440] loss: 23.841\n",
      "[6,   460] loss: 25.326\n",
      "[6,   480] loss: 25.503\n",
      "[6,   500] loss: 15.357\n",
      "[6,   520] loss: 13.359\n",
      "[6,   540] loss: 20.120\n",
      "[6,   560] loss: 10.613\n",
      "[6,   580] loss: 22.907\n",
      "[6,   600] loss: 16.550\n",
      "[6,   620] loss: 7.309\n",
      "[6,   640] loss: 17.835\n",
      "[6,   660] loss: 16.037\n",
      "[6,   680] loss: 12.102\n",
      "[6,   700] loss: 17.801\n",
      "[6,   720] loss: 14.546\n",
      "[6,   740] loss: 11.717\n",
      "[6,   760] loss: 10.719\n",
      "[6,   780] loss: 16.836\n",
      "[6,   800] loss: 20.321\n",
      "[6,   820] loss: 15.116\n",
      "[6,   840] loss: 11.272\n",
      "[6,   860] loss: 14.421\n",
      "[6,   880] loss: 7.141\n",
      "[6,   900] loss: 11.211\n",
      "[6,   920] loss: 15.470\n",
      "[6,   940] loss: 13.492\n",
      "[6,   960] loss: 15.761\n",
      "[6,   980] loss: 16.047\n",
      "[6,  1000] loss: 12.352\n",
      "[6,  1020] loss: 17.999\n",
      "[6,  1040] loss: 16.609\n",
      "[6,  1060] loss: 11.913\n",
      "[6,  1080] loss: 20.477\n",
      "[6,  1100] loss: 12.263\n",
      "[6,  1120] loss: 13.197\n",
      "[6,  1140] loss: 13.397\n",
      "[6,  1160] loss: 11.643\n",
      "[6,  1180] loss: 12.589\n",
      "[6,  1200] loss: 11.027\n",
      "[6,  1220] loss: 10.729\n",
      "[6,  1240] loss: 6.830\n",
      "[6,  1260] loss: 10.681\n",
      "[6,  1280] loss: 10.468\n",
      "[6,  1300] loss: 12.783\n",
      "[6,  1320] loss: 12.612\n",
      "[6,  1340] loss: 11.022\n",
      "[6,  1360] loss: 21.777\n",
      "[6,  1380] loss: 13.700\n",
      "[6,  1400] loss: 15.805\n",
      "[6,  1420] loss: 17.150\n",
      "[6,  1440] loss: 16.640\n",
      "[6,  1460] loss: 14.109\n",
      "[6,  1480] loss: 19.044\n",
      "[6,  1500] loss: 17.945\n",
      "[6,  1520] loss: 24.422\n",
      "[6,  1540] loss: 26.245\n",
      "[6,  1560] loss: 32.879\n",
      "[6,  1580] loss: 13.220\n",
      "[6,  1600] loss: 13.490\n",
      "[6,  1620] loss: 27.344\n",
      "[6,  1640] loss: 14.563\n",
      "[6,  1660] loss: 8.741\n",
      "[6,  1680] loss: 7.574\n",
      "[6,  1700] loss: 12.710\n",
      "[7,    20] loss: 11.961\n",
      "[7,    40] loss: 17.942\n",
      "[7,    60] loss: 19.502\n",
      "[7,    80] loss: 12.788\n",
      "[7,   100] loss: 13.943\n",
      "[7,   120] loss: 11.834\n",
      "[7,   140] loss: 10.597\n",
      "[7,   160] loss: 15.296\n",
      "[7,   180] loss: 15.750\n",
      "[7,   200] loss: 8.207\n",
      "[7,   220] loss: 9.804\n",
      "[7,   240] loss: 9.374\n",
      "[7,   260] loss: 11.580\n",
      "[7,   280] loss: 13.704\n",
      "[7,   300] loss: 6.899\n",
      "[7,   320] loss: 11.427\n",
      "[7,   340] loss: 12.500\n",
      "[7,   360] loss: 16.167\n",
      "[7,   380] loss: 13.498\n",
      "[7,   400] loss: 18.872\n",
      "[7,   420] loss: 10.072\n",
      "[7,   440] loss: 11.120\n",
      "[7,   460] loss: 13.466\n",
      "[7,   480] loss: 15.995\n",
      "[7,   500] loss: 10.131\n",
      "[7,   520] loss: 13.965\n",
      "[7,   540] loss: 15.055\n",
      "[7,   560] loss: 13.801\n",
      "[7,   580] loss: 20.164\n",
      "[7,   600] loss: 20.933\n",
      "[7,   620] loss: 10.591\n",
      "[7,   640] loss: 11.405\n",
      "[7,   660] loss: 9.120\n",
      "[7,   680] loss: 9.216\n",
      "[7,   700] loss: 10.119\n",
      "[7,   720] loss: 14.749\n",
      "[7,   740] loss: 14.198\n",
      "[7,   760] loss: 9.233\n",
      "[7,   780] loss: 12.052\n",
      "[7,   800] loss: 7.983\n",
      "[7,   820] loss: 9.481\n",
      "[7,   840] loss: 13.250\n",
      "[7,   860] loss: 11.570\n",
      "[7,   880] loss: 9.610\n",
      "[7,   900] loss: 12.554\n",
      "[7,   920] loss: 8.405\n",
      "[7,   940] loss: 9.155\n",
      "[7,   960] loss: 11.420\n",
      "[7,   980] loss: 6.339\n",
      "[7,  1000] loss: 5.989\n",
      "[7,  1020] loss: 11.951\n",
      "[7,  1040] loss: 11.195\n",
      "[7,  1060] loss: 7.341\n",
      "[7,  1080] loss: 20.223\n",
      "[7,  1100] loss: 17.621\n",
      "[7,  1120] loss: 13.589\n",
      "[7,  1140] loss: 8.989\n",
      "[7,  1160] loss: 12.875\n",
      "[7,  1180] loss: 12.703\n",
      "[7,  1200] loss: 11.292\n",
      "[7,  1220] loss: 13.116\n",
      "[7,  1240] loss: 7.320\n",
      "[7,  1260] loss: 14.645\n",
      "[7,  1280] loss: 9.143\n",
      "[7,  1300] loss: 11.836\n",
      "[7,  1320] loss: 14.825\n",
      "[7,  1340] loss: 7.145\n",
      "[7,  1360] loss: 16.605\n",
      "[7,  1380] loss: 11.152\n",
      "[7,  1400] loss: 11.526\n",
      "[7,  1420] loss: 13.761\n",
      "[7,  1440] loss: 14.770\n",
      "[7,  1460] loss: 15.103\n",
      "[7,  1480] loss: 15.837\n",
      "[7,  1500] loss: 12.371\n",
      "[7,  1520] loss: 7.383\n",
      "[7,  1540] loss: 11.369\n",
      "[7,  1560] loss: 12.565\n",
      "[7,  1580] loss: 8.745\n",
      "[7,  1600] loss: 17.916\n",
      "[7,  1620] loss: 21.077\n",
      "[7,  1640] loss: 23.661\n",
      "[7,  1660] loss: 9.124\n",
      "[7,  1680] loss: 9.650\n",
      "[7,  1700] loss: 10.559\n",
      "[8,    20] loss: 10.076\n",
      "[8,    40] loss: 14.655\n",
      "[8,    60] loss: 9.854\n",
      "[8,    80] loss: 8.738\n",
      "[8,   100] loss: 10.315\n",
      "[8,   120] loss: 9.859\n",
      "[8,   140] loss: 10.536\n",
      "[8,   160] loss: 10.997\n",
      "[8,   180] loss: 7.008\n",
      "[8,   200] loss: 5.939\n",
      "[8,   220] loss: 12.726\n",
      "[8,   240] loss: 8.833\n",
      "[8,   260] loss: 7.961\n",
      "[8,   280] loss: 9.840\n",
      "[8,   300] loss: 5.787\n",
      "[8,   320] loss: 12.374\n",
      "[8,   340] loss: 14.187\n",
      "[8,   360] loss: 15.516\n",
      "[8,   380] loss: 15.226\n",
      "[8,   400] loss: 10.730\n",
      "[8,   420] loss: 16.389\n",
      "[8,   440] loss: 25.190\n",
      "[8,   460] loss: 17.793\n",
      "[8,   480] loss: 19.816\n",
      "[8,   500] loss: 14.400\n",
      "[8,   520] loss: 14.523\n",
      "[8,   540] loss: 22.112\n",
      "[8,   560] loss: 9.405\n",
      "[8,   580] loss: 16.793\n",
      "[8,   600] loss: 16.692\n",
      "[8,   620] loss: 9.912\n",
      "[8,   640] loss: 10.439\n",
      "[8,   660] loss: 11.266\n",
      "[8,   680] loss: 11.037\n",
      "[8,   700] loss: 14.037\n",
      "[8,   720] loss: 9.876\n",
      "[8,   740] loss: 18.777\n",
      "[8,   760] loss: 7.176\n",
      "[8,   780] loss: 8.588\n",
      "[8,   800] loss: 12.995\n",
      "[8,   820] loss: 15.740\n",
      "[8,   840] loss: 15.239\n",
      "[8,   860] loss: 13.709\n",
      "[8,   880] loss: 5.278\n",
      "[8,   900] loss: 9.065\n",
      "[8,   920] loss: 15.381\n",
      "[8,   940] loss: 9.223\n",
      "[8,   960] loss: 10.636\n",
      "[8,   980] loss: 9.957\n",
      "[8,  1000] loss: 5.180\n",
      "[8,  1020] loss: 11.608\n",
      "[8,  1040] loss: 5.611\n",
      "[8,  1060] loss: 10.590\n",
      "[8,  1080] loss: 14.281\n",
      "[8,  1100] loss: 9.969\n",
      "[8,  1120] loss: 14.852\n",
      "[8,  1140] loss: 8.691\n",
      "[8,  1160] loss: 10.742\n",
      "[8,  1180] loss: 7.138\n",
      "[8,  1200] loss: 8.705\n",
      "[8,  1220] loss: 9.653\n",
      "[8,  1240] loss: 7.526\n",
      "[8,  1260] loss: 7.673\n",
      "[8,  1280] loss: 6.252\n",
      "[8,  1300] loss: 10.552\n",
      "[8,  1320] loss: 13.210\n",
      "[8,  1340] loss: 7.254\n",
      "[8,  1360] loss: 14.691\n",
      "[8,  1380] loss: 5.415\n",
      "[8,  1400] loss: 19.372\n",
      "[8,  1420] loss: 11.134\n",
      "[8,  1440] loss: 13.390\n",
      "[8,  1460] loss: 6.899\n",
      "[8,  1480] loss: 18.766\n",
      "[8,  1500] loss: 10.638\n",
      "[8,  1520] loss: 10.409\n",
      "[8,  1540] loss: 12.793\n",
      "[8,  1560] loss: 17.923\n",
      "[8,  1580] loss: 10.859\n",
      "[8,  1600] loss: 8.353\n",
      "[8,  1620] loss: 23.028\n",
      "[8,  1640] loss: 18.734\n",
      "[8,  1660] loss: 15.241\n",
      "[8,  1680] loss: 12.156\n",
      "[8,  1700] loss: 17.330\n",
      "[9,    20] loss: 18.830\n",
      "[9,    40] loss: 17.709\n",
      "[9,    60] loss: 13.912\n",
      "[9,    80] loss: 6.054\n",
      "[9,   100] loss: 17.471\n",
      "[9,   120] loss: 10.899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   140] loss: 8.108\n",
      "[9,   160] loss: 12.952\n",
      "[9,   180] loss: 23.962\n",
      "[9,   200] loss: 15.060\n",
      "[9,   220] loss: 15.768\n",
      "[9,   240] loss: 10.403\n",
      "[9,   260] loss: 11.427\n",
      "[9,   280] loss: 15.912\n",
      "[9,   300] loss: 4.544\n",
      "[9,   320] loss: 7.166\n",
      "[9,   340] loss: 8.707\n",
      "[9,   360] loss: 10.733\n",
      "[9,   380] loss: 16.895\n",
      "[9,   400] loss: 10.608\n",
      "[9,   420] loss: 11.021\n",
      "[9,   440] loss: 21.160\n",
      "[9,   460] loss: 14.730\n",
      "[9,   480] loss: 18.752\n",
      "[9,   500] loss: 10.625\n",
      "[9,   520] loss: 9.628\n",
      "[9,   540] loss: 13.286\n",
      "[9,   560] loss: 16.948\n",
      "[9,   580] loss: 18.770\n",
      "[9,   600] loss: 10.105\n",
      "[9,   620] loss: 6.385\n",
      "[9,   640] loss: 6.364\n",
      "[9,   660] loss: 9.356\n",
      "[9,   680] loss: 4.870\n",
      "[9,   700] loss: 11.646\n",
      "[9,   720] loss: 8.925\n",
      "[9,   740] loss: 18.189\n",
      "[9,   760] loss: 14.846\n",
      "[9,   780] loss: 10.606\n",
      "[9,   800] loss: 9.236\n",
      "[9,   820] loss: 5.698\n",
      "[9,   840] loss: 5.224\n",
      "[9,   860] loss: 11.851\n",
      "[9,   880] loss: 7.773\n",
      "[9,   900] loss: 11.617\n",
      "[9,   920] loss: 9.676\n",
      "[9,   940] loss: 5.141\n",
      "[9,   960] loss: 8.036\n",
      "[9,   980] loss: 8.613\n",
      "[9,  1000] loss: 7.698\n",
      "[9,  1020] loss: 10.585\n",
      "[9,  1040] loss: 6.910\n",
      "[9,  1060] loss: 9.540\n",
      "[9,  1080] loss: 21.850\n",
      "[9,  1100] loss: 13.759\n",
      "[9,  1120] loss: 14.211\n",
      "[9,  1140] loss: 11.391\n",
      "[9,  1160] loss: 13.929\n",
      "[9,  1180] loss: 7.278\n",
      "[9,  1200] loss: 8.878\n",
      "[9,  1220] loss: 11.796\n",
      "[9,  1240] loss: 5.890\n",
      "[9,  1260] loss: 7.062\n",
      "[9,  1280] loss: 8.510\n",
      "[9,  1300] loss: 4.386\n",
      "[9,  1320] loss: 13.588\n",
      "[9,  1340] loss: 27.584\n",
      "[9,  1360] loss: 28.330\n",
      "[9,  1380] loss: 29.312\n",
      "[9,  1400] loss: 20.178\n",
      "[9,  1420] loss: 15.387\n",
      "[9,  1440] loss: 12.211\n",
      "[9,  1460] loss: 15.243\n",
      "[9,  1480] loss: 16.786\n",
      "[9,  1500] loss: 17.936\n",
      "[9,  1520] loss: 6.919\n",
      "[9,  1540] loss: 7.784\n",
      "[9,  1560] loss: 11.091\n",
      "[9,  1580] loss: 6.656\n",
      "[9,  1600] loss: 12.600\n",
      "[9,  1620] loss: 13.746\n",
      "[9,  1640] loss: 16.204\n",
      "[9,  1660] loss: 10.647\n",
      "[9,  1680] loss: 6.576\n",
      "[9,  1700] loss: 10.663\n",
      "[10,    20] loss: 13.383\n",
      "[10,    40] loss: 11.399\n",
      "[10,    60] loss: 15.338\n",
      "[10,    80] loss: 10.862\n",
      "[10,   100] loss: 9.377\n",
      "[10,   120] loss: 3.864\n",
      "[10,   140] loss: 5.999\n",
      "[10,   160] loss: 10.024\n",
      "[10,   180] loss: 6.064\n",
      "[10,   200] loss: 5.478\n",
      "[10,   220] loss: 15.317\n",
      "[10,   240] loss: 6.454\n",
      "[10,   260] loss: 7.946\n",
      "[10,   280] loss: 8.044\n",
      "[10,   300] loss: 5.800\n",
      "[10,   320] loss: 11.957\n",
      "[10,   340] loss: 15.144\n",
      "[10,   360] loss: 13.906\n",
      "[10,   380] loss: 8.060\n",
      "[10,   400] loss: 11.075\n",
      "[10,   420] loss: 10.373\n",
      "[10,   440] loss: 11.472\n",
      "[10,   460] loss: 7.676\n",
      "[10,   480] loss: 10.240\n",
      "[10,   500] loss: 7.960\n",
      "[10,   520] loss: 6.907\n",
      "[10,   540] loss: 9.634\n",
      "[10,   560] loss: 11.087\n",
      "[10,   580] loss: 16.796\n",
      "[10,   600] loss: 17.379\n",
      "[10,   620] loss: 8.500\n",
      "[10,   640] loss: 8.974\n",
      "[10,   660] loss: 12.931\n",
      "[10,   680] loss: 8.757\n",
      "[10,   700] loss: 16.209\n",
      "[10,   720] loss: 25.112\n",
      "[10,   740] loss: 13.314\n",
      "[10,   760] loss: 12.012\n",
      "[10,   780] loss: 14.131\n",
      "[10,   800] loss: 8.035\n",
      "[10,   820] loss: 7.074\n",
      "[10,   840] loss: 5.592\n",
      "[10,   860] loss: 9.812\n",
      "[10,   880] loss: 12.162\n",
      "[10,   900] loss: 8.763\n",
      "[10,   920] loss: 12.579\n",
      "[10,   940] loss: 5.417\n",
      "[10,   960] loss: 6.810\n",
      "[10,   980] loss: 7.576\n",
      "[10,  1000] loss: 8.450\n",
      "[10,  1020] loss: 7.592\n",
      "[10,  1040] loss: 10.824\n",
      "[10,  1060] loss: 7.900\n",
      "[10,  1080] loss: 11.588\n",
      "[10,  1100] loss: 8.241\n",
      "[10,  1120] loss: 9.186\n",
      "[10,  1140] loss: 7.612\n",
      "[10,  1160] loss: 9.110\n",
      "[10,  1180] loss: 10.687\n",
      "[10,  1200] loss: 11.387\n",
      "[10,  1220] loss: 11.373\n",
      "[10,  1240] loss: 4.892\n",
      "[10,  1260] loss: 9.744\n",
      "[10,  1280] loss: 8.192\n",
      "[10,  1300] loss: 7.638\n",
      "[10,  1320] loss: 8.290\n",
      "[10,  1340] loss: 10.408\n",
      "[10,  1360] loss: 11.045\n",
      "[10,  1380] loss: 7.760\n",
      "[10,  1400] loss: 10.596\n",
      "[10,  1420] loss: 11.564\n",
      "[10,  1440] loss: 13.040\n",
      "[10,  1460] loss: 11.187\n",
      "[10,  1480] loss: 15.109\n",
      "[10,  1500] loss: 5.592\n",
      "[10,  1520] loss: 4.684\n",
      "[10,  1540] loss: 4.809\n",
      "[10,  1560] loss: 10.349\n",
      "[10,  1580] loss: 6.851\n",
      "[10,  1600] loss: 8.518\n",
      "[10,  1620] loss: 17.558\n",
      "[10,  1640] loss: 14.512\n",
      "[10,  1660] loss: 8.696\n",
      "[10,  1680] loss: 8.207\n",
      "[10,  1700] loss: 8.406\n",
      "validation set accuracy (33575 samples): 98.4482501861504\n"
     ]
    }
   ],
   "source": [
    "training_dataset_batch, training_labels_batch = create_batches(xTrainingSet, yTrainingSet, batch_size)\n",
    "validation_dataset_batch, validation_labels_batch = create_batches(xValidationSet, yValidationSet, batch_size)\n",
    "\n",
    "# model hyper-parameters\n",
    "h_layers = ([batch_size, 64])\n",
    "max_iters = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "# train neural network\n",
    "net = Net(h_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "for epoch in range(max_iters):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(training_dataset_batch):\n",
    "        inputs = torch.from_numpy(data)\n",
    "        labels = training_labels_batch[i] \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, torch.from_numpy(np.array(labels).astype(np.longlong)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 20 == 19:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "# test validation set on model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(validation_dataset_batch):\n",
    "        images = torch.from_numpy(data)\n",
    "        labels = validation_labels_batch[i]\n",
    "        labels = torch.from_numpy(np.array(labels).astype(np.longlong))\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if (int(predicted[0]) != int(labels[0])):\n",
    "            None\n",
    "\n",
    "print(f\"validation set accuracy ({total} samples): {(100 * correct / total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN to predict unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 4859.397\n",
      "[1,    40] loss: 926.832\n",
      "[1,    60] loss: 474.009\n",
      "[1,    80] loss: 439.571\n",
      "[1,   100] loss: 289.454\n",
      "[1,   120] loss: 254.074\n",
      "[1,   140] loss: 275.664\n",
      "[1,   160] loss: 249.180\n",
      "[1,   180] loss: 172.999\n",
      "[1,   200] loss: 195.440\n",
      "[1,   220] loss: 252.527\n",
      "[1,   240] loss: 200.027\n",
      "[1,   260] loss: 230.944\n",
      "[1,   280] loss: 158.561\n",
      "[1,   300] loss: 107.421\n",
      "[1,   320] loss: 131.672\n",
      "[1,   340] loss: 150.120\n",
      "[1,   360] loss: 146.536\n",
      "[1,   380] loss: 100.907\n",
      "[1,   400] loss: 115.567\n",
      "[1,   420] loss: 92.568\n",
      "[1,   440] loss: 95.775\n",
      "[1,   460] loss: 85.689\n",
      "[1,   480] loss: 130.626\n",
      "[1,   500] loss: 112.734\n",
      "[1,   520] loss: 110.116\n",
      "[1,   540] loss: 118.167\n",
      "[1,   560] loss: 131.960\n",
      "[1,   580] loss: 122.312\n",
      "[1,   600] loss: 106.005\n",
      "[1,   620] loss: 116.770\n",
      "[1,   640] loss: 101.190\n",
      "[1,   660] loss: 99.094\n",
      "[1,   680] loss: 98.599\n",
      "[1,   700] loss: 103.920\n",
      "[1,   720] loss: 78.762\n",
      "[1,   740] loss: 83.648\n",
      "[1,   760] loss: 59.049\n",
      "[1,   780] loss: 54.365\n",
      "[1,   800] loss: 53.128\n",
      "[1,   820] loss: 48.553\n",
      "[1,   840] loss: 75.429\n",
      "[1,   860] loss: 56.099\n",
      "[1,   880] loss: 64.601\n",
      "[1,   900] loss: 50.476\n",
      "[1,   920] loss: 64.070\n",
      "[1,   940] loss: 41.878\n",
      "[1,   960] loss: 40.327\n",
      "[1,   980] loss: 57.878\n",
      "[1,  1000] loss: 46.655\n",
      "[1,  1020] loss: 48.981\n",
      "[1,  1040] loss: 62.938\n",
      "[1,  1060] loss: 60.149\n",
      "[1,  1080] loss: 64.550\n",
      "[1,  1100] loss: 95.702\n",
      "[1,  1120] loss: 70.776\n",
      "[1,  1140] loss: 52.439\n",
      "[1,  1160] loss: 44.255\n",
      "[1,  1180] loss: 62.173\n",
      "[1,  1200] loss: 55.756\n",
      "[1,  1220] loss: 49.535\n",
      "[1,  1240] loss: 54.255\n",
      "[1,  1260] loss: 48.689\n",
      "[1,  1280] loss: 47.126\n",
      "[1,  1300] loss: 51.388\n",
      "[1,  1320] loss: 41.254\n",
      "[1,  1340] loss: 60.229\n",
      "[1,  1360] loss: 56.174\n",
      "[1,  1380] loss: 59.556\n",
      "[1,  1400] loss: 42.838\n",
      "[1,  1420] loss: 57.970\n",
      "[1,  1440] loss: 53.906\n",
      "[1,  1460] loss: 41.570\n",
      "[1,  1480] loss: 60.652\n",
      "[1,  1500] loss: 70.454\n",
      "[1,  1520] loss: 63.686\n",
      "[1,  1540] loss: 52.165\n",
      "[1,  1560] loss: 52.888\n",
      "[1,  1580] loss: 40.808\n",
      "[1,  1600] loss: 51.770\n",
      "[1,  1620] loss: 71.033\n",
      "[1,  1640] loss: 68.616\n",
      "[1,  1660] loss: 58.871\n",
      "[1,  1680] loss: 48.471\n",
      "[1,  1700] loss: 53.204\n",
      "[1,  1720] loss: 61.695\n",
      "[1,  1740] loss: 47.558\n",
      "[1,  1760] loss: 53.667\n",
      "[1,  1780] loss: 52.576\n",
      "[1,  1800] loss: 68.882\n",
      "[1,  1820] loss: 68.503\n",
      "[1,  1840] loss: 86.250\n",
      "[1,  1860] loss: 94.968\n",
      "[1,  1880] loss: 70.044\n",
      "[1,  1900] loss: 72.710\n",
      "[1,  1920] loss: 58.367\n",
      "[1,  1940] loss: 51.047\n",
      "[1,  1960] loss: 44.509\n",
      "[1,  1980] loss: 45.880\n",
      "[1,  2000] loss: 46.472\n",
      "[1,  2020] loss: 48.607\n",
      "[1,  2040] loss: 43.172\n",
      "[1,  2060] loss: 46.899\n",
      "[1,  2080] loss: 28.225\n",
      "[1,  2100] loss: 33.125\n",
      "[1,  2120] loss: 38.536\n",
      "[2,    20] loss: 39.530\n",
      "[2,    40] loss: 38.743\n",
      "[2,    60] loss: 29.961\n",
      "[2,    80] loss: 46.836\n",
      "[2,   100] loss: 44.479\n",
      "[2,   120] loss: 31.218\n",
      "[2,   140] loss: 47.115\n",
      "[2,   160] loss: 64.851\n",
      "[2,   180] loss: 50.330\n",
      "[2,   200] loss: 37.176\n",
      "[2,   220] loss: 46.920\n",
      "[2,   240] loss: 24.127\n",
      "[2,   260] loss: 49.483\n",
      "[2,   280] loss: 41.330\n",
      "[2,   300] loss: 22.283\n",
      "[2,   320] loss: 37.548\n",
      "[2,   340] loss: 44.778\n",
      "[2,   360] loss: 37.274\n",
      "[2,   380] loss: 29.998\n",
      "[2,   400] loss: 32.693\n",
      "[2,   420] loss: 30.197\n",
      "[2,   440] loss: 39.521\n",
      "[2,   460] loss: 34.030\n",
      "[2,   480] loss: 40.416\n",
      "[2,   500] loss: 36.223\n",
      "[2,   520] loss: 45.182\n",
      "[2,   540] loss: 44.887\n",
      "[2,   560] loss: 40.832\n",
      "[2,   580] loss: 49.078\n",
      "[2,   600] loss: 29.609\n",
      "[2,   620] loss: 27.967\n",
      "[2,   640] loss: 29.355\n",
      "[2,   660] loss: 25.942\n",
      "[2,   680] loss: 41.015\n",
      "[2,   700] loss: 54.065\n",
      "[2,   720] loss: 39.198\n",
      "[2,   740] loss: 29.689\n",
      "[2,   760] loss: 41.932\n",
      "[2,   780] loss: 30.851\n",
      "[2,   800] loss: 32.179\n",
      "[2,   820] loss: 31.195\n",
      "[2,   840] loss: 32.139\n",
      "[2,   860] loss: 21.631\n",
      "[2,   880] loss: 33.973\n",
      "[2,   900] loss: 31.711\n",
      "[2,   920] loss: 32.062\n",
      "[2,   940] loss: 33.573\n",
      "[2,   960] loss: 40.593\n",
      "[2,   980] loss: 25.443\n",
      "[2,  1000] loss: 42.984\n",
      "[2,  1020] loss: 51.354\n",
      "[2,  1040] loss: 46.638\n",
      "[2,  1060] loss: 34.253\n",
      "[2,  1080] loss: 62.650\n",
      "[2,  1100] loss: 49.021\n",
      "[2,  1120] loss: 28.448\n",
      "[2,  1140] loss: 36.211\n",
      "[2,  1160] loss: 38.533\n",
      "[2,  1180] loss: 42.126\n",
      "[2,  1200] loss: 15.608\n",
      "[2,  1220] loss: 28.817\n",
      "[2,  1240] loss: 20.547\n",
      "[2,  1260] loss: 41.303\n",
      "[2,  1280] loss: 36.984\n",
      "[2,  1300] loss: 21.622\n",
      "[2,  1320] loss: 16.263\n",
      "[2,  1340] loss: 18.942\n",
      "[2,  1360] loss: 37.376\n",
      "[2,  1380] loss: 46.474\n",
      "[2,  1400] loss: 36.157\n",
      "[2,  1420] loss: 34.422\n",
      "[2,  1440] loss: 33.104\n",
      "[2,  1460] loss: 25.381\n",
      "[2,  1480] loss: 41.487\n",
      "[2,  1500] loss: 59.979\n",
      "[2,  1520] loss: 42.621\n",
      "[2,  1540] loss: 35.750\n",
      "[2,  1560] loss: 44.576\n",
      "[2,  1580] loss: 33.333\n",
      "[2,  1600] loss: 29.953\n",
      "[2,  1620] loss: 37.835\n",
      "[2,  1640] loss: 38.055\n",
      "[2,  1660] loss: 29.433\n",
      "[2,  1680] loss: 23.399\n",
      "[2,  1700] loss: 30.011\n",
      "[2,  1720] loss: 30.128\n",
      "[2,  1740] loss: 37.358\n",
      "[2,  1760] loss: 30.415\n",
      "[2,  1780] loss: 23.571\n",
      "[2,  1800] loss: 41.568\n",
      "[2,  1820] loss: 40.728\n",
      "[2,  1840] loss: 31.830\n",
      "[2,  1860] loss: 16.805\n",
      "[2,  1880] loss: 32.254\n",
      "[2,  1900] loss: 36.467\n",
      "[2,  1920] loss: 30.356\n",
      "[2,  1940] loss: 32.030\n",
      "[2,  1960] loss: 27.122\n",
      "[2,  1980] loss: 34.609\n",
      "[2,  2000] loss: 26.467\n",
      "[2,  2020] loss: 37.533\n",
      "[2,  2040] loss: 23.782\n",
      "[2,  2060] loss: 23.852\n",
      "[2,  2080] loss: 17.996\n",
      "[2,  2100] loss: 19.705\n",
      "[2,  2120] loss: 24.841\n",
      "[3,    20] loss: 28.515\n",
      "[3,    40] loss: 29.260\n",
      "[3,    60] loss: 24.832\n",
      "[3,    80] loss: 41.456\n",
      "[3,   100] loss: 26.966\n",
      "[3,   120] loss: 21.237\n",
      "[3,   140] loss: 30.810\n",
      "[3,   160] loss: 45.478\n",
      "[3,   180] loss: 30.074\n",
      "[3,   200] loss: 29.032\n",
      "[3,   220] loss: 28.784\n",
      "[3,   240] loss: 14.840\n",
      "[3,   260] loss: 26.292\n",
      "[3,   280] loss: 33.625\n",
      "[3,   300] loss: 21.543\n",
      "[3,   320] loss: 24.833\n",
      "[3,   340] loss: 28.891\n",
      "[3,   360] loss: 22.906\n",
      "[3,   380] loss: 16.719\n",
      "[3,   400] loss: 27.293\n",
      "[3,   420] loss: 19.005\n",
      "[3,   440] loss: 35.369\n",
      "[3,   460] loss: 47.755\n",
      "[3,   480] loss: 32.304\n",
      "[3,   500] loss: 41.806\n",
      "[3,   520] loss: 42.083\n",
      "[3,   540] loss: 45.588\n",
      "[3,   560] loss: 35.329\n",
      "[3,   580] loss: 54.476\n",
      "[3,   600] loss: 35.933\n",
      "[3,   620] loss: 21.726\n",
      "[3,   640] loss: 29.896\n",
      "[3,   660] loss: 26.742\n",
      "[3,   680] loss: 21.636\n",
      "[3,   700] loss: 34.907\n",
      "[3,   720] loss: 23.044\n",
      "[3,   740] loss: 33.112\n",
      "[3,   760] loss: 39.742\n",
      "[3,   780] loss: 30.290\n",
      "[3,   800] loss: 25.303\n",
      "[3,   820] loss: 17.393\n",
      "[3,   840] loss: 20.484\n",
      "[3,   860] loss: 20.916\n",
      "[3,   880] loss: 16.278\n",
      "[3,   900] loss: 17.832\n",
      "[3,   920] loss: 22.202\n",
      "[3,   940] loss: 31.024\n",
      "[3,   960] loss: 20.253\n",
      "[3,   980] loss: 20.079\n",
      "[3,  1000] loss: 28.897\n",
      "[3,  1020] loss: 23.617\n",
      "[3,  1040] loss: 37.087\n",
      "[3,  1060] loss: 23.114\n",
      "[3,  1080] loss: 18.733\n",
      "[3,  1100] loss: 18.260\n",
      "[3,  1120] loss: 19.370\n",
      "[3,  1140] loss: 24.724\n",
      "[3,  1160] loss: 18.578\n",
      "[3,  1180] loss: 29.086\n",
      "[3,  1200] loss: 25.290\n",
      "[3,  1220] loss: 33.712\n",
      "[3,  1240] loss: 18.336\n",
      "[3,  1260] loss: 24.948\n",
      "[3,  1280] loss: 20.751\n",
      "[3,  1300] loss: 14.426\n",
      "[3,  1320] loss: 19.169\n",
      "[3,  1340] loss: 8.632\n",
      "[3,  1360] loss: 21.716\n",
      "[3,  1380] loss: 21.625\n",
      "[3,  1400] loss: 27.656\n",
      "[3,  1420] loss: 32.155\n",
      "[3,  1440] loss: 50.848\n",
      "[3,  1460] loss: 38.805\n",
      "[3,  1480] loss: 44.764\n",
      "[3,  1500] loss: 45.376\n",
      "[3,  1520] loss: 50.414\n",
      "[3,  1540] loss: 32.260\n",
      "[3,  1560] loss: 38.777\n",
      "[3,  1580] loss: 21.765\n",
      "[3,  1600] loss: 23.284\n",
      "[3,  1620] loss: 30.023\n",
      "[3,  1640] loss: 25.519\n",
      "[3,  1660] loss: 19.795\n",
      "[3,  1680] loss: 18.469\n",
      "[3,  1700] loss: 29.755\n",
      "[3,  1720] loss: 17.500\n",
      "[3,  1740] loss: 18.530\n",
      "[3,  1760] loss: 27.543\n",
      "[3,  1780] loss: 26.663\n",
      "[3,  1800] loss: 36.075\n",
      "[3,  1820] loss: 26.829\n",
      "[3,  1840] loss: 40.046\n",
      "[3,  1860] loss: 26.207\n",
      "[3,  1880] loss: 17.231\n",
      "[3,  1900] loss: 23.882\n",
      "[3,  1920] loss: 20.686\n",
      "[3,  1940] loss: 23.356\n",
      "[3,  1960] loss: 18.873\n",
      "[3,  1980] loss: 23.053\n",
      "[3,  2000] loss: 19.050\n",
      "[3,  2020] loss: 21.243\n",
      "[3,  2040] loss: 17.316\n",
      "[3,  2060] loss: 23.460\n",
      "[3,  2080] loss: 12.043\n",
      "[3,  2100] loss: 13.958\n",
      "[3,  2120] loss: 26.623\n",
      "[4,    20] loss: 26.346\n",
      "[4,    40] loss: 21.142\n",
      "[4,    60] loss: 14.533\n",
      "[4,    80] loss: 14.516\n",
      "[4,   100] loss: 18.978\n",
      "[4,   120] loss: 10.881\n",
      "[4,   140] loss: 18.744\n",
      "[4,   160] loss: 23.419\n",
      "[4,   180] loss: 18.549\n",
      "[4,   200] loss: 11.571\n",
      "[4,   220] loss: 23.145\n",
      "[4,   240] loss: 18.325\n",
      "[4,   260] loss: 29.209\n",
      "[4,   280] loss: 25.354\n",
      "[4,   300] loss: 18.076\n",
      "[4,   320] loss: 34.234\n",
      "[4,   340] loss: 30.731\n",
      "[4,   360] loss: 25.494\n",
      "[4,   380] loss: 17.811\n",
      "[4,   400] loss: 23.249\n",
      "[4,   420] loss: 11.872\n",
      "[4,   440] loss: 27.038\n",
      "[4,   460] loss: 20.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   480] loss: 28.410\n",
      "[4,   500] loss: 23.403\n",
      "[4,   520] loss: 17.271\n",
      "[4,   540] loss: 41.545\n",
      "[4,   560] loss: 25.673\n",
      "[4,   580] loss: 37.687\n",
      "[4,   600] loss: 33.989\n",
      "[4,   620] loss: 21.219\n",
      "[4,   640] loss: 18.185\n",
      "[4,   660] loss: 12.148\n",
      "[4,   680] loss: 17.512\n",
      "[4,   700] loss: 35.213\n",
      "[4,   720] loss: 28.941\n",
      "[4,   740] loss: 30.535\n",
      "[4,   760] loss: 27.322\n",
      "[4,   780] loss: 25.368\n",
      "[4,   800] loss: 15.915\n",
      "[4,   820] loss: 15.886\n",
      "[4,   840] loss: 11.934\n",
      "[4,   860] loss: 18.112\n",
      "[4,   880] loss: 14.117\n",
      "[4,   900] loss: 14.172\n",
      "[4,   920] loss: 17.927\n",
      "[4,   940] loss: 26.501\n",
      "[4,   960] loss: 20.092\n",
      "[4,   980] loss: 18.021\n",
      "[4,  1000] loss: 21.784\n",
      "[4,  1020] loss: 20.353\n",
      "[4,  1040] loss: 16.909\n",
      "[4,  1060] loss: 10.463\n",
      "[4,  1080] loss: 24.591\n",
      "[4,  1100] loss: 22.154\n",
      "[4,  1120] loss: 20.690\n",
      "[4,  1140] loss: 16.939\n",
      "[4,  1160] loss: 22.745\n",
      "[4,  1180] loss: 28.848\n",
      "[4,  1200] loss: 21.768\n",
      "[4,  1220] loss: 17.065\n",
      "[4,  1240] loss: 17.397\n",
      "[4,  1260] loss: 21.403\n",
      "[4,  1280] loss: 17.208\n",
      "[4,  1300] loss: 15.743\n",
      "[4,  1320] loss: 9.674\n",
      "[4,  1340] loss: 11.955\n",
      "[4,  1360] loss: 18.287\n",
      "[4,  1380] loss: 14.055\n",
      "[4,  1400] loss: 22.205\n",
      "[4,  1420] loss: 18.477\n",
      "[4,  1440] loss: 23.485\n",
      "[4,  1460] loss: 24.669\n",
      "[4,  1480] loss: 23.730\n",
      "[4,  1500] loss: 19.836\n",
      "[4,  1520] loss: 15.284\n",
      "[4,  1540] loss: 14.780\n",
      "[4,  1560] loss: 18.151\n",
      "[4,  1580] loss: 12.562\n",
      "[4,  1600] loss: 13.416\n",
      "[4,  1620] loss: 27.291\n",
      "[4,  1640] loss: 25.995\n",
      "[4,  1660] loss: 15.784\n",
      "[4,  1680] loss: 13.015\n",
      "[4,  1700] loss: 18.831\n",
      "[4,  1720] loss: 18.869\n",
      "[4,  1740] loss: 24.616\n",
      "[4,  1760] loss: 9.802\n",
      "[4,  1780] loss: 11.920\n",
      "[4,  1800] loss: 20.648\n",
      "[4,  1820] loss: 19.632\n",
      "[4,  1840] loss: 21.114\n",
      "[4,  1860] loss: 23.386\n",
      "[4,  1880] loss: 19.156\n",
      "[4,  1900] loss: 25.283\n",
      "[4,  1920] loss: 21.861\n",
      "[4,  1940] loss: 15.449\n",
      "[4,  1960] loss: 19.903\n",
      "[4,  1980] loss: 16.423\n",
      "[4,  2000] loss: 16.629\n",
      "[4,  2020] loss: 21.915\n",
      "[4,  2040] loss: 20.904\n",
      "[4,  2060] loss: 28.479\n",
      "[4,  2080] loss: 10.026\n",
      "[4,  2100] loss: 10.650\n",
      "[4,  2120] loss: 14.262\n",
      "[5,    20] loss: 21.115\n",
      "[5,    40] loss: 21.902\n",
      "[5,    60] loss: 13.721\n",
      "[5,    80] loss: 16.154\n",
      "[5,   100] loss: 26.225\n",
      "[5,   120] loss: 18.545\n",
      "[5,   140] loss: 14.163\n",
      "[5,   160] loss: 18.087\n",
      "[5,   180] loss: 24.203\n",
      "[5,   200] loss: 8.753\n",
      "[5,   220] loss: 21.734\n",
      "[5,   240] loss: 11.439\n",
      "[5,   260] loss: 20.302\n",
      "[5,   280] loss: 21.157\n",
      "[5,   300] loss: 6.891\n",
      "[5,   320] loss: 16.897\n",
      "[5,   340] loss: 16.601\n",
      "[5,   360] loss: 17.523\n",
      "[5,   380] loss: 22.882\n",
      "[5,   400] loss: 16.526\n",
      "[5,   420] loss: 14.362\n",
      "[5,   440] loss: 18.927\n",
      "[5,   460] loss: 18.788\n",
      "[5,   480] loss: 28.142\n",
      "[5,   500] loss: 19.032\n",
      "[5,   520] loss: 15.102\n",
      "[5,   540] loss: 29.956\n",
      "[5,   560] loss: 27.002\n",
      "[5,   580] loss: 35.411\n",
      "[5,   600] loss: 23.785\n",
      "[5,   620] loss: 11.145\n",
      "[5,   640] loss: 12.135\n",
      "[5,   660] loss: 14.945\n",
      "[5,   680] loss: 16.626\n",
      "[5,   700] loss: 25.331\n",
      "[5,   720] loss: 18.943\n",
      "[5,   740] loss: 20.777\n",
      "[5,   760] loss: 19.540\n",
      "[5,   780] loss: 22.690\n",
      "[5,   800] loss: 15.063\n",
      "[5,   820] loss: 18.710\n",
      "[5,   840] loss: 19.370\n",
      "[5,   860] loss: 23.853\n",
      "[5,   880] loss: 20.127\n",
      "[5,   900] loss: 22.922\n",
      "[5,   920] loss: 15.378\n",
      "[5,   940] loss: 17.678\n",
      "[5,   960] loss: 10.532\n",
      "[5,   980] loss: 14.510\n",
      "[5,  1000] loss: 13.250\n",
      "[5,  1020] loss: 23.199\n",
      "[5,  1040] loss: 25.886\n",
      "[5,  1060] loss: 23.887\n",
      "[5,  1080] loss: 37.598\n",
      "[5,  1100] loss: 27.751\n",
      "[5,  1120] loss: 14.000\n",
      "[5,  1140] loss: 13.131\n",
      "[5,  1160] loss: 17.900\n",
      "[5,  1180] loss: 17.423\n",
      "[5,  1200] loss: 15.887\n",
      "[5,  1220] loss: 22.884\n",
      "[5,  1240] loss: 11.283\n",
      "[5,  1260] loss: 22.923\n",
      "[5,  1280] loss: 11.699\n",
      "[5,  1300] loss: 11.256\n",
      "[5,  1320] loss: 12.285\n",
      "[5,  1340] loss: 11.409\n",
      "[5,  1360] loss: 17.439\n",
      "[5,  1380] loss: 11.153\n",
      "[5,  1400] loss: 19.708\n",
      "[5,  1420] loss: 18.808\n",
      "[5,  1440] loss: 19.664\n",
      "[5,  1460] loss: 19.883\n",
      "[5,  1480] loss: 18.688\n",
      "[5,  1500] loss: 18.257\n",
      "[5,  1520] loss: 24.348\n",
      "[5,  1540] loss: 29.494\n",
      "[5,  1560] loss: 32.547\n",
      "[5,  1580] loss: 13.671\n",
      "[5,  1600] loss: 10.278\n",
      "[5,  1620] loss: 31.155\n",
      "[5,  1640] loss: 25.840\n",
      "[5,  1660] loss: 22.184\n",
      "[5,  1680] loss: 16.828\n",
      "[5,  1700] loss: 17.716\n",
      "[5,  1720] loss: 16.416\n",
      "[5,  1740] loss: 22.841\n",
      "[5,  1760] loss: 24.839\n",
      "[5,  1780] loss: 19.122\n",
      "[5,  1800] loss: 17.338\n",
      "[5,  1820] loss: 12.666\n",
      "[5,  1840] loss: 21.438\n",
      "[5,  1860] loss: 7.470\n",
      "[5,  1880] loss: 19.634\n",
      "[5,  1900] loss: 24.132\n",
      "[5,  1920] loss: 15.165\n",
      "[5,  1940] loss: 15.537\n",
      "[5,  1960] loss: 17.114\n",
      "[5,  1980] loss: 15.358\n",
      "[5,  2000] loss: 18.422\n",
      "[5,  2020] loss: 19.207\n",
      "[5,  2040] loss: 25.356\n",
      "[5,  2060] loss: 26.531\n",
      "[5,  2080] loss: 17.914\n",
      "[5,  2100] loss: 10.484\n",
      "[5,  2120] loss: 13.766\n",
      "[6,    20] loss: 23.868\n",
      "[6,    40] loss: 16.605\n",
      "[6,    60] loss: 9.115\n",
      "[6,    80] loss: 13.468\n",
      "[6,   100] loss: 18.469\n",
      "[6,   120] loss: 12.732\n",
      "[6,   140] loss: 19.834\n",
      "[6,   160] loss: 13.085\n",
      "[6,   180] loss: 16.468\n",
      "[6,   200] loss: 10.019\n",
      "[6,   220] loss: 14.867\n",
      "[6,   240] loss: 8.099\n",
      "[6,   260] loss: 17.274\n",
      "[6,   280] loss: 15.896\n",
      "[6,   300] loss: 12.453\n",
      "[6,   320] loss: 16.887\n",
      "[6,   340] loss: 21.844\n",
      "[6,   360] loss: 17.053\n",
      "[6,   380] loss: 13.973\n",
      "[6,   400] loss: 12.942\n",
      "[6,   420] loss: 12.906\n",
      "[6,   440] loss: 20.486\n",
      "[6,   460] loss: 21.258\n",
      "[6,   480] loss: 17.003\n",
      "[6,   500] loss: 22.019\n",
      "[6,   520] loss: 16.618\n",
      "[6,   540] loss: 30.197\n",
      "[6,   560] loss: 22.808\n",
      "[6,   580] loss: 22.536\n",
      "[6,   600] loss: 16.010\n",
      "[6,   620] loss: 7.419\n",
      "[6,   640] loss: 7.295\n",
      "[6,   660] loss: 15.744\n",
      "[6,   680] loss: 14.540\n",
      "[6,   700] loss: 25.610\n",
      "[6,   720] loss: 18.653\n",
      "[6,   740] loss: 25.559\n",
      "[6,   760] loss: 20.544\n",
      "[6,   780] loss: 16.017\n",
      "[6,   800] loss: 17.018\n",
      "[6,   820] loss: 11.848\n",
      "[6,   840] loss: 15.056\n",
      "[6,   860] loss: 15.574\n",
      "[6,   880] loss: 13.597\n",
      "[6,   900] loss: 15.805\n",
      "[6,   920] loss: 16.943\n",
      "[6,   940] loss: 20.418\n",
      "[6,   960] loss: 23.586\n",
      "[6,   980] loss: 13.807\n",
      "[6,  1000] loss: 11.546\n",
      "[6,  1020] loss: 15.880\n",
      "[6,  1040] loss: 12.066\n",
      "[6,  1060] loss: 9.627\n",
      "[6,  1080] loss: 15.930\n",
      "[6,  1100] loss: 15.489\n",
      "[6,  1120] loss: 14.137\n",
      "[6,  1140] loss: 18.891\n",
      "[6,  1160] loss: 16.403\n",
      "[6,  1180] loss: 13.522\n",
      "[6,  1200] loss: 14.259\n",
      "[6,  1220] loss: 15.570\n",
      "[6,  1240] loss: 9.093\n",
      "[6,  1260] loss: 17.210\n",
      "[6,  1280] loss: 9.806\n",
      "[6,  1300] loss: 11.159\n",
      "[6,  1320] loss: 8.178\n",
      "[6,  1340] loss: 8.561\n",
      "[6,  1360] loss: 23.616\n",
      "[6,  1380] loss: 14.262\n",
      "[6,  1400] loss: 16.807\n",
      "[6,  1420] loss: 19.157\n",
      "[6,  1440] loss: 17.037\n",
      "[6,  1460] loss: 18.304\n",
      "[6,  1480] loss: 19.909\n",
      "[6,  1500] loss: 16.726\n",
      "[6,  1520] loss: 23.677\n",
      "[6,  1540] loss: 14.383\n",
      "[6,  1560] loss: 15.096\n",
      "[6,  1580] loss: 12.218\n",
      "[6,  1600] loss: 18.173\n",
      "[6,  1620] loss: 19.694\n",
      "[6,  1640] loss: 17.126\n",
      "[6,  1660] loss: 16.212\n",
      "[6,  1680] loss: 12.455\n",
      "[6,  1700] loss: 13.065\n",
      "[6,  1720] loss: 20.178\n",
      "[6,  1740] loss: 28.548\n",
      "[6,  1760] loss: 15.370\n",
      "[6,  1780] loss: 9.041\n",
      "[6,  1800] loss: 15.398\n",
      "[6,  1820] loss: 7.617\n",
      "[6,  1840] loss: 22.257\n",
      "[6,  1860] loss: 8.101\n",
      "[6,  1880] loss: 17.162\n",
      "[6,  1900] loss: 14.589\n",
      "[6,  1920] loss: 16.085\n",
      "[6,  1940] loss: 23.263\n",
      "[6,  1960] loss: 20.243\n",
      "[6,  1980] loss: 18.517\n",
      "[6,  2000] loss: 14.346\n",
      "[6,  2020] loss: 17.492\n",
      "[6,  2040] loss: 15.527\n",
      "[6,  2060] loss: 18.598\n",
      "[6,  2080] loss: 11.098\n",
      "[6,  2100] loss: 10.154\n",
      "[6,  2120] loss: 11.731\n",
      "[7,    20] loss: 22.413\n",
      "[7,    40] loss: 17.202\n",
      "[7,    60] loss: 9.197\n",
      "[7,    80] loss: 10.558\n",
      "[7,   100] loss: 12.845\n",
      "[7,   120] loss: 12.170\n",
      "[7,   140] loss: 21.561\n",
      "[7,   160] loss: 14.821\n",
      "[7,   180] loss: 19.805\n",
      "[7,   200] loss: 6.989\n",
      "[7,   220] loss: 20.126\n",
      "[7,   240] loss: 9.234\n",
      "[7,   260] loss: 17.559\n",
      "[7,   280] loss: 22.352\n",
      "[7,   300] loss: 7.824\n",
      "[7,   320] loss: 18.156\n",
      "[7,   340] loss: 13.134\n",
      "[7,   360] loss: 28.630\n",
      "[7,   380] loss: 16.918\n",
      "[7,   400] loss: 13.878\n",
      "[7,   420] loss: 9.400\n",
      "[7,   440] loss: 17.706\n",
      "[7,   460] loss: 18.465\n",
      "[7,   480] loss: 18.799\n",
      "[7,   500] loss: 22.910\n",
      "[7,   520] loss: 21.085\n",
      "[7,   540] loss: 25.389\n",
      "[7,   560] loss: 21.179\n",
      "[7,   580] loss: 19.752\n",
      "[7,   600] loss: 14.110\n",
      "[7,   620] loss: 5.070\n",
      "[7,   640] loss: 11.281\n",
      "[7,   660] loss: 13.423\n",
      "[7,   680] loss: 11.575\n",
      "[7,   700] loss: 20.237\n",
      "[7,   720] loss: 17.168\n",
      "[7,   740] loss: 17.200\n",
      "[7,   760] loss: 12.735\n",
      "[7,   780] loss: 13.847\n",
      "[7,   800] loss: 15.257\n",
      "[7,   820] loss: 6.317\n",
      "[7,   840] loss: 11.010\n",
      "[7,   860] loss: 14.697\n",
      "[7,   880] loss: 10.369\n",
      "[7,   900] loss: 11.659\n",
      "[7,   920] loss: 10.185\n",
      "[7,   940] loss: 9.659\n",
      "[7,   960] loss: 8.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   980] loss: 8.906\n",
      "[7,  1000] loss: 13.941\n",
      "[7,  1020] loss: 16.807\n",
      "[7,  1040] loss: 11.747\n",
      "[7,  1060] loss: 8.358\n",
      "[7,  1080] loss: 14.181\n",
      "[7,  1100] loss: 11.833\n",
      "[7,  1120] loss: 8.271\n",
      "[7,  1140] loss: 11.611\n",
      "[7,  1160] loss: 18.210\n",
      "[7,  1180] loss: 16.182\n",
      "[7,  1200] loss: 10.359\n",
      "[7,  1220] loss: 13.645\n",
      "[7,  1240] loss: 3.863\n",
      "[7,  1260] loss: 12.737\n",
      "[7,  1280] loss: 6.320\n",
      "[7,  1300] loss: 12.616\n",
      "[7,  1320] loss: 8.479\n",
      "[7,  1340] loss: 11.135\n",
      "[7,  1360] loss: 16.800\n",
      "[7,  1380] loss: 12.177\n",
      "[7,  1400] loss: 14.356\n",
      "[7,  1420] loss: 14.951\n",
      "[7,  1440] loss: 16.769\n",
      "[7,  1460] loss: 13.250\n",
      "[7,  1480] loss: 18.307\n",
      "[7,  1500] loss: 11.811\n",
      "[7,  1520] loss: 11.958\n",
      "[7,  1540] loss: 12.395\n",
      "[7,  1560] loss: 13.016\n",
      "[7,  1580] loss: 11.687\n",
      "[7,  1600] loss: 19.876\n",
      "[7,  1620] loss: 25.503\n",
      "[7,  1640] loss: 20.002\n",
      "[7,  1660] loss: 11.821\n",
      "[7,  1680] loss: 8.252\n",
      "[7,  1700] loss: 10.799\n",
      "[7,  1720] loss: 13.294\n",
      "[7,  1740] loss: 17.090\n",
      "[7,  1760] loss: 13.136\n",
      "[7,  1780] loss: 6.283\n",
      "[7,  1800] loss: 15.787\n",
      "[7,  1820] loss: 13.584\n",
      "[7,  1840] loss: 21.536\n",
      "[7,  1860] loss: 8.842\n",
      "[7,  1880] loss: 14.043\n",
      "[7,  1900] loss: 11.750\n",
      "[7,  1920] loss: 13.006\n",
      "[7,  1940] loss: 12.816\n",
      "[7,  1960] loss: 21.519\n",
      "[7,  1980] loss: 24.219\n",
      "[7,  2000] loss: 20.574\n",
      "[7,  2020] loss: 17.760\n",
      "[7,  2040] loss: 17.141\n",
      "[7,  2060] loss: 12.921\n",
      "[7,  2080] loss: 9.773\n",
      "[7,  2100] loss: 7.046\n",
      "[7,  2120] loss: 13.304\n",
      "[8,    20] loss: 25.514\n",
      "[8,    40] loss: 31.009\n",
      "[8,    60] loss: 14.935\n",
      "[8,    80] loss: 14.846\n",
      "[8,   100] loss: 13.607\n",
      "[8,   120] loss: 10.602\n",
      "[8,   140] loss: 17.750\n",
      "[8,   160] loss: 18.595\n",
      "[8,   180] loss: 19.564\n",
      "[8,   200] loss: 9.122\n",
      "[8,   220] loss: 15.275\n",
      "[8,   240] loss: 9.674\n",
      "[8,   260] loss: 18.792\n",
      "[8,   280] loss: 12.284\n",
      "[8,   300] loss: 7.307\n",
      "[8,   320] loss: 12.279\n",
      "[8,   340] loss: 8.466\n",
      "[8,   360] loss: 12.082\n",
      "[8,   380] loss: 10.047\n",
      "[8,   400] loss: 13.186\n",
      "[8,   420] loss: 17.117\n",
      "[8,   440] loss: 19.990\n",
      "[8,   460] loss: 13.268\n",
      "[8,   480] loss: 24.541\n",
      "[8,   500] loss: 25.025\n",
      "[8,   520] loss: 13.949\n",
      "[8,   540] loss: 26.854\n",
      "[8,   560] loss: 20.410\n",
      "[8,   580] loss: 15.254\n",
      "[8,   600] loss: 19.050\n",
      "[8,   620] loss: 8.062\n",
      "[8,   640] loss: 11.366\n",
      "[8,   660] loss: 9.015\n",
      "[8,   680] loss: 15.705\n",
      "[8,   700] loss: 15.608\n",
      "[8,   720] loss: 24.416\n",
      "[8,   740] loss: 25.310\n",
      "[8,   760] loss: 15.412\n",
      "[8,   780] loss: 15.458\n",
      "[8,   800] loss: 8.431\n",
      "[8,   820] loss: 5.822\n",
      "[8,   840] loss: 11.174\n",
      "[8,   860] loss: 11.492\n",
      "[8,   880] loss: 8.932\n",
      "[8,   900] loss: 12.222\n",
      "[8,   920] loss: 12.597\n",
      "[8,   940] loss: 9.743\n",
      "[8,   960] loss: 11.515\n",
      "[8,   980] loss: 6.919\n",
      "[8,  1000] loss: 10.747\n",
      "[8,  1020] loss: 13.223\n",
      "[8,  1040] loss: 12.947\n",
      "[8,  1060] loss: 4.837\n",
      "[8,  1080] loss: 25.546\n",
      "[8,  1100] loss: 17.632\n",
      "[8,  1120] loss: 12.057\n",
      "[8,  1140] loss: 18.725\n",
      "[8,  1160] loss: 14.477\n",
      "[8,  1180] loss: 8.974\n",
      "[8,  1200] loss: 18.318\n",
      "[8,  1220] loss: 12.681\n",
      "[8,  1240] loss: 5.672\n",
      "[8,  1260] loss: 11.420\n",
      "[8,  1280] loss: 6.647\n",
      "[8,  1300] loss: 8.496\n",
      "[8,  1320] loss: 6.331\n",
      "[8,  1340] loss: 8.681\n",
      "[8,  1360] loss: 18.987\n",
      "[8,  1380] loss: 15.809\n",
      "[8,  1400] loss: 14.788\n",
      "[8,  1420] loss: 9.726\n",
      "[8,  1440] loss: 11.784\n",
      "[8,  1460] loss: 19.828\n",
      "[8,  1480] loss: 19.701\n",
      "[8,  1500] loss: 12.400\n",
      "[8,  1520] loss: 14.794\n",
      "[8,  1540] loss: 11.898\n",
      "[8,  1560] loss: 17.901\n",
      "[8,  1580] loss: 4.187\n",
      "[8,  1600] loss: 7.101\n",
      "[8,  1620] loss: 21.248\n",
      "[8,  1640] loss: 12.511\n",
      "[8,  1660] loss: 7.099\n",
      "[8,  1680] loss: 7.668\n",
      "[8,  1700] loss: 11.051\n",
      "[8,  1720] loss: 9.849\n",
      "[8,  1740] loss: 11.692\n",
      "[8,  1760] loss: 10.409\n",
      "[8,  1780] loss: 11.417\n",
      "[8,  1800] loss: 11.294\n",
      "[8,  1820] loss: 11.752\n",
      "[8,  1840] loss: 18.194\n",
      "[8,  1860] loss: 9.122\n",
      "[8,  1880] loss: 11.106\n",
      "[8,  1900] loss: 16.198\n",
      "[8,  1920] loss: 9.150\n",
      "[8,  1940] loss: 10.314\n",
      "[8,  1960] loss: 22.301\n",
      "[8,  1980] loss: 16.754\n",
      "[8,  2000] loss: 12.256\n",
      "[8,  2020] loss: 17.787\n",
      "[8,  2040] loss: 15.104\n",
      "[8,  2060] loss: 17.550\n",
      "[8,  2080] loss: 10.180\n",
      "[8,  2100] loss: 9.227\n",
      "[8,  2120] loss: 17.793\n",
      "[9,    20] loss: 11.238\n",
      "[9,    40] loss: 15.314\n",
      "[9,    60] loss: 9.578\n",
      "[9,    80] loss: 10.758\n",
      "[9,   100] loss: 17.044\n",
      "[9,   120] loss: 13.863\n",
      "[9,   140] loss: 10.688\n",
      "[9,   160] loss: 10.783\n",
      "[9,   180] loss: 19.684\n",
      "[9,   200] loss: 13.016\n",
      "[9,   220] loss: 13.901\n",
      "[9,   240] loss: 14.449\n",
      "[9,   260] loss: 12.076\n",
      "[9,   280] loss: 11.394\n",
      "[9,   300] loss: 6.540\n",
      "[9,   320] loss: 9.501\n",
      "[9,   340] loss: 8.989\n",
      "[9,   360] loss: 17.105\n",
      "[9,   380] loss: 15.400\n",
      "[9,   400] loss: 13.056\n",
      "[9,   420] loss: 18.358\n",
      "[9,   440] loss: 17.486\n",
      "[9,   460] loss: 17.651\n",
      "[9,   480] loss: 16.223\n",
      "[9,   500] loss: 11.832\n",
      "[9,   520] loss: 15.410\n",
      "[9,   540] loss: 21.252\n",
      "[9,   560] loss: 12.182\n",
      "[9,   580] loss: 16.120\n",
      "[9,   600] loss: 13.491\n",
      "[9,   620] loss: 9.570\n",
      "[9,   640] loss: 7.114\n",
      "[9,   660] loss: 5.370\n",
      "[9,   680] loss: 7.631\n",
      "[9,   700] loss: 13.360\n",
      "[9,   720] loss: 11.188\n",
      "[9,   740] loss: 17.564\n",
      "[9,   760] loss: 14.994\n",
      "[9,   780] loss: 13.351\n",
      "[9,   800] loss: 7.940\n",
      "[9,   820] loss: 6.015\n",
      "[9,   840] loss: 12.926\n",
      "[9,   860] loss: 13.417\n",
      "[9,   880] loss: 10.117\n",
      "[9,   900] loss: 9.805\n",
      "[9,   920] loss: 11.345\n",
      "[9,   940] loss: 10.192\n",
      "[9,   960] loss: 14.017\n",
      "[9,   980] loss: 13.967\n",
      "[9,  1000] loss: 8.944\n",
      "[9,  1020] loss: 14.305\n",
      "[9,  1040] loss: 11.856\n",
      "[9,  1060] loss: 9.017\n",
      "[9,  1080] loss: 23.723\n",
      "[9,  1100] loss: 14.635\n",
      "[9,  1120] loss: 13.084\n",
      "[9,  1140] loss: 14.280\n",
      "[9,  1160] loss: 11.325\n",
      "[9,  1180] loss: 11.404\n",
      "[9,  1200] loss: 12.476\n",
      "[9,  1220] loss: 10.815\n",
      "[9,  1240] loss: 4.651\n",
      "[9,  1260] loss: 11.765\n",
      "[9,  1280] loss: 8.629\n",
      "[9,  1300] loss: 7.103\n",
      "[9,  1320] loss: 6.497\n",
      "[9,  1340] loss: 4.981\n",
      "[9,  1360] loss: 23.244\n",
      "[9,  1380] loss: 14.769\n",
      "[9,  1400] loss: 14.788\n",
      "[9,  1420] loss: 14.077\n",
      "[9,  1440] loss: 13.066\n",
      "[9,  1460] loss: 17.793\n",
      "[9,  1480] loss: 17.063\n",
      "[9,  1500] loss: 11.968\n",
      "[9,  1520] loss: 8.508\n",
      "[9,  1540] loss: 9.487\n",
      "[9,  1560] loss: 12.618\n",
      "[9,  1580] loss: 5.949\n",
      "[9,  1600] loss: 9.811\n",
      "[9,  1620] loss: 17.242\n",
      "[9,  1640] loss: 15.835\n",
      "[9,  1660] loss: 7.979\n",
      "[9,  1680] loss: 6.797\n",
      "[9,  1700] loss: 8.843\n",
      "[9,  1720] loss: 10.778\n",
      "[9,  1740] loss: 22.166\n",
      "[9,  1760] loss: 15.420\n",
      "[9,  1780] loss: 8.612\n",
      "[9,  1800] loss: 10.811\n",
      "[9,  1820] loss: 5.888\n",
      "[9,  1840] loss: 18.115\n",
      "[9,  1860] loss: 10.592\n",
      "[9,  1880] loss: 14.829\n",
      "[9,  1900] loss: 16.088\n",
      "[9,  1920] loss: 11.315\n",
      "[9,  1940] loss: 9.727\n",
      "[9,  1960] loss: 10.787\n",
      "[9,  1980] loss: 16.258\n",
      "[9,  2000] loss: 11.640\n",
      "[9,  2020] loss: 13.485\n",
      "[9,  2040] loss: 14.144\n",
      "[9,  2060] loss: 9.842\n",
      "[9,  2080] loss: 6.402\n",
      "[9,  2100] loss: 4.727\n",
      "[9,  2120] loss: 11.922\n",
      "[10,    20] loss: 16.243\n",
      "[10,    40] loss: 16.758\n",
      "[10,    60] loss: 6.197\n",
      "[10,    80] loss: 10.821\n",
      "[10,   100] loss: 11.021\n",
      "[10,   120] loss: 8.823\n",
      "[10,   140] loss: 8.140\n",
      "[10,   160] loss: 8.448\n",
      "[10,   180] loss: 17.380\n",
      "[10,   200] loss: 8.870\n",
      "[10,   220] loss: 9.568\n",
      "[10,   240] loss: 9.848\n",
      "[10,   260] loss: 9.323\n",
      "[10,   280] loss: 7.144\n",
      "[10,   300] loss: 8.260\n",
      "[10,   320] loss: 9.538\n",
      "[10,   340] loss: 9.517\n",
      "[10,   360] loss: 12.283\n",
      "[10,   380] loss: 7.548\n",
      "[10,   400] loss: 12.159\n",
      "[10,   420] loss: 13.602\n",
      "[10,   440] loss: 11.889\n",
      "[10,   460] loss: 11.654\n",
      "[10,   480] loss: 21.291\n",
      "[10,   500] loss: 21.713\n",
      "[10,   520] loss: 16.661\n",
      "[10,   540] loss: 22.871\n",
      "[10,   560] loss: 8.952\n",
      "[10,   580] loss: 11.895\n",
      "[10,   600] loss: 9.777\n",
      "[10,   620] loss: 5.122\n",
      "[10,   640] loss: 7.702\n",
      "[10,   660] loss: 13.072\n",
      "[10,   680] loss: 8.777\n",
      "[10,   700] loss: 11.872\n",
      "[10,   720] loss: 13.532\n",
      "[10,   740] loss: 18.909\n",
      "[10,   760] loss: 13.243\n",
      "[10,   780] loss: 11.704\n",
      "[10,   800] loss: 12.566\n",
      "[10,   820] loss: 9.769\n",
      "[10,   840] loss: 17.464\n",
      "[10,   860] loss: 8.196\n",
      "[10,   880] loss: 9.384\n",
      "[10,   900] loss: 12.979\n",
      "[10,   920] loss: 6.361\n",
      "[10,   940] loss: 7.130\n",
      "[10,   960] loss: 13.078\n",
      "[10,   980] loss: 11.278\n",
      "[10,  1000] loss: 11.596\n",
      "[10,  1020] loss: 13.300\n",
      "[10,  1040] loss: 8.080\n",
      "[10,  1060] loss: 3.588\n",
      "[10,  1080] loss: 7.897\n",
      "[10,  1100] loss: 10.192\n",
      "[10,  1120] loss: 9.391\n",
      "[10,  1140] loss: 11.713\n",
      "[10,  1160] loss: 12.081\n",
      "[10,  1180] loss: 12.050\n",
      "[10,  1200] loss: 15.512\n",
      "[10,  1220] loss: 8.006\n",
      "[10,  1240] loss: 5.603\n",
      "[10,  1260] loss: 12.743\n",
      "[10,  1280] loss: 3.887\n",
      "[10,  1300] loss: 6.932\n",
      "[10,  1320] loss: 5.354\n",
      "[10,  1340] loss: 3.671\n",
      "[10,  1360] loss: 15.180\n",
      "[10,  1380] loss: 8.692\n",
      "[10,  1400] loss: 12.003\n",
      "[10,  1420] loss: 10.754\n",
      "[10,  1440] loss: 12.168\n",
      "[10,  1460] loss: 12.400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,  1480] loss: 16.013\n",
      "[10,  1500] loss: 9.262\n",
      "[10,  1520] loss: 6.138\n",
      "[10,  1540] loss: 8.643\n",
      "[10,  1560] loss: 12.086\n",
      "[10,  1580] loss: 7.998\n",
      "[10,  1600] loss: 8.680\n",
      "[10,  1620] loss: 15.873\n",
      "[10,  1640] loss: 10.082\n",
      "[10,  1660] loss: 8.077\n",
      "[10,  1680] loss: 8.142\n",
      "[10,  1700] loss: 7.816\n",
      "[10,  1720] loss: 9.922\n",
      "[10,  1740] loss: 16.151\n",
      "[10,  1760] loss: 9.664\n",
      "[10,  1780] loss: 11.514\n",
      "[10,  1800] loss: 10.325\n",
      "[10,  1820] loss: 5.525\n",
      "[10,  1840] loss: 17.256\n",
      "[10,  1860] loss: 13.537\n",
      "[10,  1880] loss: 17.137\n",
      "[10,  1900] loss: 12.264\n",
      "[10,  1920] loss: 13.763\n",
      "[10,  1940] loss: 17.592\n",
      "[10,  1960] loss: 14.027\n",
      "[10,  1980] loss: 8.548\n",
      "[10,  2000] loss: 10.574\n",
      "[10,  2020] loss: 15.588\n",
      "[10,  2040] loss: 8.726\n",
      "[10,  2060] loss: 10.407\n",
      "[10,  2080] loss: 8.252\n",
      "[10,  2100] loss: 9.910\n",
      "[10,  2120] loss: 10.409\n"
     ]
    }
   ],
   "source": [
    "full_dataset = xTrainingSet + xValidationSet\n",
    "full_labels = yTrainingSet + yValidationSet\n",
    "\n",
    "full_dataset_batch, full_labels_batch = create_batches(full_dataset, full_labels, batch_size)\n",
    "\n",
    "net = Net(h_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "for epoch in range(max_iters):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(full_dataset_batch):\n",
    "        inputs = torch.from_numpy(data)\n",
    "        labels = full_labels_batch[i] \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, torch.from_numpy(np.array(labels).astype(np.longlong)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 20 == 19:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated_digits = []\n",
    "\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    digits = []\n",
    "    \n",
    "    images, n_digits = find_digits(sample, 25)\n",
    "   \n",
    "    for i, image in enumerate(images):\n",
    "        modified_image = image[7:19,7:19]\n",
    "        digits.append(modified_image)\n",
    "        \n",
    "    separated_digits.append(digits)\n",
    "    \n",
    "results = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    results.append([])\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "    \n",
    "for i in range(int(num_test_digits / batch_size)):\n",
    "    batch = []\n",
    "    source = []\n",
    "    count = 0\n",
    "    \n",
    "    while count < batch_size:\n",
    "        batch.append(separated_digits[row][col])\n",
    "        source.append((row, col))\n",
    "        \n",
    "        if(col < len(separated_digits[row]) - 1):\n",
    "            col += 1\n",
    "        else:\n",
    "            row += 1\n",
    "            col = 0\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    batch = np.expand_dims(np.asarray(batch).astype(np.single), axis=1) \n",
    "    batch = torch.from_numpy(batch)\n",
    "    \n",
    "    output = net(batch)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    for j, pred in enumerate(predicted):\n",
    "        coord = source[j]\n",
    "        results[coord[0]].append(pred.item())\n",
    "        \n",
    "for r in results:\n",
    "    pad = 5 - len(r)\n",
    "    \n",
    "    for i in range(pad):\n",
    "        r.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(test_dataset):\n",
    "    displayGreyWindows(sample, \"\")\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810101010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10101010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>468810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "0  810101010\n",
       "1     317310\n",
       "2     408310\n",
       "3   10101010\n",
       "4     468810"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(str(results[0]))\n",
    "\n",
    "Id = []\n",
    "label = []\n",
    "for i, x in enumerate(results):\n",
    "    Id.append(i)\n",
    "    string = ''.join([str(elem) for elem in x])\n",
    "    label.append(int(string))\n",
    "\"\"\"\n",
    "print(Id[0],label[0])\n",
    "print(df[\"Label\"])\n",
    "\"\"\"\n",
    "data={\"Label\":label}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('sample.csv', index_label = \"Id\")\n",
    "df.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
