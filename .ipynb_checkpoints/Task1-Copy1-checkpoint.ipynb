{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import numpy.linalg as lia\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#to plot images\n",
    "import matplotlib.image as mpimg \n",
    "#to read images\n",
    "\n",
    "import cv2 \n",
    "#open CV library for Python\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.ops import nms\n",
    "import torchvision.transforms as transforms\n",
    "from statistics import stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.4.0.44 in d:\\anaconda3\\envs\\pytorch37\\lib\\site-packages (4.4.0.44)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\david\\appdata\\roaming\\python\\python37\\site-packages (from opencv-python==4.4.0.44) (1.18.5)\n",
      "Requirement already satisfied: opencv-contrib-python==4.4.0.44 in d:\\anaconda3\\envs\\pytorch37\\lib\\site-packages (4.4.0.44)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\david\\appdata\\roaming\\python\\python37\\site-packages (from opencv-contrib-python==4.4.0.44) (1.18.5)\n",
      "Package                Version\n",
      "---------------------- -------------------\n",
      "-pencv-python          4.4.0.46\n",
      "absl-py                0.11.0\n",
      "argon2-cffi            20.1.0\n",
      "astunparse             1.6.3\n",
      "async-generator        1.10\n",
      "attrs                  20.3.0\n",
      "backcall               0.2.0\n",
      "bleach                 3.2.1\n",
      "cachetools             4.1.1\n",
      "certifi                2020.12.5\n",
      "cffi                   1.14.4\n",
      "chardet                3.0.4\n",
      "cloudpickle            1.6.0\n",
      "colorama               0.4.4\n",
      "cycler                 0.10.0\n",
      "cytoolz                0.11.0\n",
      "dask                   2020.12.0\n",
      "decorator              4.4.2\n",
      "defusedxml             0.6.0\n",
      "entrypoints            0.3\n",
      "gast                   0.3.3\n",
      "google-auth            1.23.0\n",
      "google-auth-oauthlib   0.4.2\n",
      "google-pasta           0.2.0\n",
      "grpcio                 1.34.0\n",
      "h5py                   2.10.0\n",
      "idna                   2.10\n",
      "imagecodecs            2020.5.30\n",
      "imageio                2.9.0\n",
      "importlib-metadata     2.0.0\n",
      "imutils                0.5.3\n",
      "ipykernel              5.3.4\n",
      "ipython                7.19.0\n",
      "ipython-genutils       0.2.0\n",
      "jedi                   0.17.2\n",
      "Jinja2                 2.11.2\n",
      "joblib                 0.17.0\n",
      "jsonschema             3.2.0\n",
      "jupyter-client         6.1.7\n",
      "jupyter-core           4.7.0\n",
      "jupyterlab-pygments    0.1.2\n",
      "Keras-Preprocessing    1.1.2\n",
      "kiwisolver             1.3.1\n",
      "Markdown               3.3.3\n",
      "MarkupSafe             1.1.1\n",
      "matplotlib             3.3.3\n",
      "mistune                0.8.4\n",
      "mkl-fft                1.2.0\n",
      "mkl-random             1.1.1\n",
      "mkl-service            2.3.0\n",
      "nbclient               0.5.1\n",
      "nbconvert              6.0.7\n",
      "nbformat               5.0.8\n",
      "nest-asyncio           1.4.3\n",
      "networkx               2.5\n",
      "notebook               6.1.4\n",
      "numpy                  1.18.5\n",
      "oauthlib               3.1.0\n",
      "olefile                0.46\n",
      "opencv-contrib-python  4.4.0.44\n",
      "opencv-python          4.4.0.44\n",
      "opt-einsum             3.3.0\n",
      "packaging              20.7\n",
      "pandas                 1.1.3\n",
      "pandocfilters          1.4.3\n",
      "parso                  0.7.0\n",
      "pickleshare            0.7.5\n",
      "Pillow                 8.0.1\n",
      "pip                    20.3.1\n",
      "prometheus-client      0.9.0\n",
      "prompt-toolkit         3.0.8\n",
      "protobuf               3.14.0\n",
      "pyasn1                 0.4.8\n",
      "pyasn1-modules         0.2.8\n",
      "pycparser              2.20\n",
      "Pygments               2.7.3\n",
      "pyparsing              2.4.7\n",
      "pyreadline             2.1\n",
      "pyrsistent             0.17.3\n",
      "python-dateutil        2.8.1\n",
      "pytz                   2020.4\n",
      "PyWavelets             1.1.1\n",
      "pywin32                227\n",
      "pywinpty               0.5.7\n",
      "PyYAML                 5.3.1\n",
      "pyzmq                  20.0.0\n",
      "requests               2.25.0\n",
      "requests-oauthlib      1.3.0\n",
      "rsa                    4.6\n",
      "scikit-image           0.17.2\n",
      "scikit-learn           0.23.2\n",
      "scipy                  1.5.4\n",
      "Send2Trash             1.5.0\n",
      "setuptools             51.0.0.post20201207\n",
      "six                    1.15.0\n",
      "tensorboard            2.4.0\n",
      "tensorboard-plugin-wit 1.7.0\n",
      "tensorflow             2.3.1\n",
      "tensorflow-estimator   2.3.0\n",
      "termcolor              1.1.0\n",
      "terminado              0.9.1\n",
      "testpath               0.4.4\n",
      "threadpoolctl          2.1.0\n",
      "tifffile               2020.12.4\n",
      "toolz                  0.11.1\n",
      "torch                  1.7.1\n",
      "torchaudio             0.7.2\n",
      "torchvision            0.8.2\n",
      "tornado                6.1\n",
      "traitlets              5.0.5\n",
      "typing-extensions      3.7.4.3\n",
      "urllib3                1.26.2\n",
      "wcwidth                0.2.5\n",
      "webencodings           0.5.1\n",
      "Werkzeug               1.0.1\n",
      "wheel                  0.36.1\n",
      "wincertstore           0.2\n",
      "wrapt                  1.12.1\n",
      "zipp                   3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python==4.4.0.44\n",
    "!pip install opencv-contrib-python==4.4.0.44\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBGRImage(path):\n",
    "    image = BGR(cv.imread(path))\n",
    "    return image\n",
    "\n",
    "def loadGreyImage(path):\n",
    "    image = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "    return image\n",
    "\n",
    "def BGR(image):\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    return image\n",
    "\n",
    "def displayGreyImage(image, imageName):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "\n",
    "def displayGreyWindows(image, imageName):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "    \n",
    "def displayBGRImage(image, imageName, size):\n",
    "    plt.figure(figsize=(size, size))\n",
    "    plt.imshow(image)\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "    \n",
    "def displayBGRImageLarge(image, imageName):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    plt.imshow(image)\n",
    "    plt.title(imageName)\n",
    "    plt.show()\n",
    "    \n",
    "def imageSideBySide(images, imageNames,size):\n",
    "    row = np.ceil(len(images)/20)\n",
    "    fig=plt.figure(figsize=(size, size/2))\n",
    "    for i, image in enumerate(images):\n",
    "        fig.add_subplot(row, 20, i+1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title(imageNames[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_dataset', 'train_dataset', 'train_labels']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 25, 26\n",
    "size = 14, 12\n",
    "\n",
    "f = h5py.File('MNIST_synthetic.h5', 'r')\n",
    "\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.squeeze(np.array(f[\"train_dataset\"])).copy()\n",
    "train_labels = np.squeeze(np.array(f[\"train_labels\"])).copy()\n",
    "test_dataset = np.squeeze(np.array(f[\"test_dataset\"])).copy()\n",
    "\n",
    "singulars_digits = []\n",
    "singulars_labels = []\n",
    "\n",
    "doubles_digits = []\n",
    "doubles_labels = []\n",
    "\n",
    "triples_digits = []\n",
    "triples_labels = []\n",
    "\n",
    "quadruples_digits = []\n",
    "quadruples_labels = []\n",
    "\n",
    "quintuples_digits = []\n",
    "quintuples_labels = []\n",
    "\n",
    "\n",
    "for i, labels in enumerate(train_labels):\n",
    "    if labels[1] == 10:\n",
    "        singulars_digits.append(train_dataset[i])\n",
    "        singulars_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[1] != 10 and labels[2] == 10:\n",
    "        doubles_digits.append(train_dataset[i])\n",
    "        doubles_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[2] != 10 and labels[3] == 10:\n",
    "        triples_digits.append(train_dataset[i])\n",
    "        triples_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[3] != 10 and labels[4] == 10:\n",
    "        quadruples_digits.append(train_dataset[i])\n",
    "        quadruples_labels.append(train_labels[i])\n",
    "        \n",
    "    if labels[4] != 10:\n",
    "        quintuples_digits.append(train_dataset[i])\n",
    "        quintuples_labels.append(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "singulars_digits = np.array(singulars_digits)     \n",
    "doubles_digits = np.array(doubles_digits)  \n",
    "triples_digits = np.array(triples_digits)    \n",
    "quadruples_digits = np.array(quadruples_digits)    \n",
    "quintuples_digits = np.array(quintuples_digits)    \n",
    "\n",
    "singulars_labels = np.array(singulars_labels).T[0]\n",
    "doubles_labels = np.array(doubles_labels).T[0:2].T\n",
    "triples_label = np.array(triples_labels).T[0:3].T\n",
    "quadruples_label = np.array(quadruples_labels).T[0:4].T\n",
    "quintuples_label = np.array(quintuples_labels).T[0:5].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_singulars_dataset = []\n",
    "final_singulars_labels = list(singulars_labels)\n",
    "for i, digit in enumerate(singulars_digits):\n",
    "    final_singulars_dataset.append(digit[26:38,26:38])\n",
    "    \n",
    "final_doubles_dataset = []\n",
    "final_doubles_labels = []\n",
    "for i, digit in enumerate(doubles_digits):\n",
    "    final_doubles_dataset.append(digit[26:38,20:32])\n",
    "    final_doubles_dataset.append(digit[26:38,32:44])\n",
    "    final_doubles_labels.append(doubles_labels[i][0])\n",
    "    final_doubles_labels.append(doubles_labels[i][1])\n",
    "\n",
    "final_triples_dataset = []\n",
    "final_triples_labels = []\n",
    "for i, digit in enumerate(triples_digits):\n",
    "    final_triples_dataset.append(digit[26:38,14:26])\n",
    "    final_triples_dataset.append(digit[26:38,26:38])\n",
    "    final_triples_dataset.append(digit[26:38,38:50])\n",
    "    final_triples_labels.append(triples_labels[i][0])\n",
    "    final_triples_labels.append(triples_labels[i][1])\n",
    "    final_triples_labels.append(triples_labels[i][2])\n",
    "    \n",
    "final_quadruples_dataset = []\n",
    "final_quadruples_labels = []\n",
    "for i, digit in enumerate(quadruples_digits):\n",
    "    final_quadruples_dataset.append(digit[26:38,8:20])\n",
    "    final_quadruples_dataset.append(digit[26:38,20:32])\n",
    "    final_quadruples_dataset.append(digit[26:38,32:44])\n",
    "    final_quadruples_dataset.append(digit[26:38,44:56])\n",
    "    final_quadruples_labels.append(quadruples_labels[i][0])\n",
    "    final_quadruples_labels.append(quadruples_labels[i][1])    \n",
    "    final_quadruples_labels.append(quadruples_labels[i][2])\n",
    "    final_quadruples_labels.append(quadruples_labels[i][3]) \n",
    "    \n",
    "final_quintuples_dataset = []\n",
    "final_quintuples_labels = []\n",
    "for i, digit in enumerate(quintuples_digits):\n",
    "    final_quintuples_dataset.append(digit[26:38,2:14])\n",
    "    final_quintuples_dataset.append(digit[26:38,14:26])\n",
    "    final_quintuples_dataset.append(digit[26:38,26:38])\n",
    "    final_quintuples_dataset.append(digit[26:38,38:50])\n",
    "    final_quintuples_dataset.append(digit[26:38,50:62])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][0])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][1])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][2])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][3])\n",
    "    final_quintuples_labels.append(quintuples_labels[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = final_singulars_dataset + final_doubles_dataset + final_triples_dataset + final_quadruples_dataset + final_quintuples_dataset\n",
    "merged_labels = final_singulars_labels + final_doubles_labels + final_triples_labels + final_quadruples_labels + final_quintuples_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of 0's in train dataset: 16379\n",
      "number of 1's in train dataset: 18819\n",
      "number of 2's in train dataset: 17095\n",
      "number of 3's in train dataset: 17220\n",
      "number of 4's in train dataset: 16393\n",
      "number of 5's in train dataset: 15275\n",
      "number of 6's in train dataset: 16401\n",
      "number of 7's in train dataset: 17611\n",
      "number of 8's in train dataset: 16175\n",
      "number of 9's in train dataset: 16518\n",
      "total number of digits in train dataset: 167886\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for digit in range(10):\n",
    "    digit_count = list(merged_labels).count(digit)\n",
    "    print(f\"number of {digit}'s in train dataset: {digit_count}\")\n",
    "    count += digit_count\n",
    "\n",
    "print(\"total number of digits in train dataset:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitsTrainingSetSize = int(np.ceil(0.8 * len(merged_dataset)))\n",
    "digitsValidationSetSize = int(len(merged_labels) - digitsTrainingSetSize)\n",
    "\n",
    "xValidationSet = []\n",
    "yValidationSet = []\n",
    "\n",
    "for index, digit in enumerate(merged_dataset[0:digitsValidationSetSize]):\n",
    "    xValidationSet.append(digit)\n",
    "    yValidationSet.append(merged_labels[index])\n",
    "\n",
    "xTrainingSet = []\n",
    "yTrainingSet = []\n",
    "\n",
    "start = len(xValidationSet)\n",
    "\n",
    "for i, digit in enumerate(merged_dataset[start:]):\n",
    "    xTrainingSet.append(digit)\n",
    "    yTrainingSet.append(merged_labels[i+start])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding all digits in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_digits(train_dataset, size):\n",
    "    thresh_train_dataset = train_dataset.copy()\n",
    "    thresh_train_dataset[thresh_train_dataset>30] = 255\n",
    "    thresh_train_dataset[thresh_train_dataset!=255] = 0\n",
    "    #displayGreyImage(thresh_train_dataset,\"\")\n",
    "    i,j = np.where(thresh_train_dataset[:,:]!=0)\n",
    "    #print(i)\n",
    "    bottom_bound = np.min(i)\n",
    "    top_bound = np.max(i)\n",
    "    left_bound = np.min(j)\n",
    "    right_bound = np.max(j)\n",
    "    #print(top_bound, bottom_bound)\n",
    "\n",
    "    h = top_bound-bottom_bound\n",
    "    w = right_bound-left_bound\n",
    "\n",
    "    bounded_train_dataset = train_dataset[bottom_bound-1:top_bound+2,left_bound-1:right_bound+2]\n",
    "    thresh = bounded_train_dataset.copy()\n",
    "    thresh[thresh>30] = 255\n",
    "    thresh[thresh!=255] = 0\n",
    "    #displayGreyImage(bounded_train_dataset,\"\")\n",
    "\n",
    "    #ret, thresh = cv2.threshold(bounded_train_dataset, 30, 255, 0)\n",
    "    #seg = np.where(np.any(thresh, axis=0)==0)\n",
    "    seg = np.where(np.any(thresh, axis=0)==0)\n",
    "\n",
    "    #print(seg)\n",
    "    seg_list = np.asarray(seg)\n",
    "    seg_list = seg_list[0]\n",
    "    #print(seg_list)\n",
    "\n",
    "    from statistics import stdev\n",
    "    sd =0 # remove this and its return when done\n",
    "    if len(seg_list)>2:\n",
    "        # create a list of the gaps between the consecutive values\n",
    "        gaps = [y - x for x, y in zip(seg_list[:-1], seg_list[1:])]\n",
    "        # have python calculate the standard deviation for the gaps\n",
    "        sd = stdev(gaps)\n",
    "        #print(sd)\n",
    "\n",
    "        # create a list of lists, put the first value of the source data in the first\n",
    "        lists = [[seg_list[0]]]\n",
    "        for x in seg_list[1:]:\n",
    "            # if the gap from the current item to the previous is more than 1 SD\n",
    "            # Note: the previous item is the last item in the last list\n",
    "            # Note: the '> 1' is the part you'd modify to make it stricter or more relaxed\n",
    "            if sd<1.5 and sd>0:\n",
    "                if (x - lists[-1][-1]) / (sd+1e-18) > 1.5:\n",
    "                    # then start a new list\n",
    "                    lists.append([])\n",
    "              # add the current item to the last list in the list\n",
    "                lists[-1].append(x)\n",
    "            elif sd==0:\n",
    "                if (x - lists[-1][-1])>1:\n",
    "                    lists.append([])\n",
    "                lists[-1].append(x)\n",
    "            else:\n",
    "                if (x - lists[-1][-1]) / (sd+1e-18) > 0.8:\n",
    "                  # then start a new list\n",
    "                  lists.append([])\n",
    "                # add the current item to the last list in the list\n",
    "                lists[-1].append(x)\n",
    "\n",
    "        splits = np.asarray([np.ceil(np.mean(lists[i])) for i in range(len(lists))]).astype(int)\n",
    "\n",
    "    else:\n",
    "        splits = np.asarray(seg_list)\n",
    "      #print(splits)\n",
    "\n",
    "    n_digits = len(splits)-1\n",
    "    #digits = np.zeros(n_digits, )\n",
    "    digits = []\n",
    "    for i in range(n_digits):\n",
    "        temp = bounded_train_dataset[:,splits[i]:splits[i+1]]\n",
    "        # if temp is less than recommeded size first pad on left and then on both sides\n",
    "        temp_padded = temp.copy()\n",
    "        if (temp.shape[0] != size) or  (temp.shape[1] != size):\n",
    "            diff_y = size-temp.shape[0]\n",
    "            split_diff_y = diff_y//2\n",
    "            remainder_diff_y = diff_y%2\n",
    "            diff_x = size-temp.shape[1]\n",
    "            split_diff_x = diff_x//2\n",
    "            remainder_diff_x = diff_x%2\n",
    "            #print(diff_y)\n",
    "            #print(split_diff_y)\n",
    "            temp_padded = np.pad(temp, ((split_diff_y+remainder_diff_y,split_diff_y),(split_diff_x+remainder_diff_x,split_diff_x)))\n",
    "\n",
    "        digits.append(temp_padded)\n",
    "      #displayGreyImage(train_dataset[bottom_bound-1:top_bound+2,left_bound-1:right_bound+2],train_labels[367])\n",
    "    return digits, n_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxes_hacks(image, dig_centers):\n",
    "    \n",
    "    n_dig = len(dig_centers)\n",
    "    digits = []\n",
    "    if n_dig == 1:\n",
    "        digits.append(image[26:38,26:38])\n",
    "    elif n_dig == 2:\n",
    "        digits.append(image[26:38,20:32])\n",
    "        digits.append(image[26:38,32:44])\n",
    "    elif n_dig == 3:\n",
    "        digits.append(image[26:38,14:26])\n",
    "        digits.append(image[26:38,26:38])\n",
    "        digits.append(image[26:38,38:50])\n",
    "    elif n_dig == 4:\n",
    "        digits.append(image[26:38,8:20])\n",
    "        digits.append(image[26:38,20:32])\n",
    "        digits.append(image[26:38,32:44])\n",
    "        digits.append(image[26:38,44:56])\n",
    "    elif n_dig == 5:\n",
    "        digits.append(image[26:38,2:14])\n",
    "        digits.append(image[26:38,14:26])\n",
    "        digits.append(image[26:38,26:38])\n",
    "        digits.append(image[26:38,38:50])\n",
    "        digits.append(image[26:38,50:62])\n",
    "\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rng\n",
    "rng.seed(12345)\n",
    "def thresh_callback(src, val=30):\n",
    "    threshold = val\n",
    "\n",
    "    src_gray = cv2.blur(src, (1,1))\n",
    "\n",
    "    #src_gray = bounding_box(src_gray,30)\n",
    "\n",
    "    canny_output = cv2.Canny(src_gray, threshold, threshold * 2)\n",
    "    \n",
    "    \n",
    "    contours, _ = cv2.findContours(canny_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    contours_poly = [None]*len(contours)\n",
    "    boundRect = [None]*len(contours)\n",
    "    centers = [None]*len(contours)\n",
    "    radius = [None]*len(contours)\n",
    "    for i, c in enumerate(contours):\n",
    "        contours_poly[i] = cv2.approxPolyDP(c, 3, True)\n",
    "        boundRect[i] = cv2.boundingRect(contours_poly[i])\n",
    "        centers[i], radius[i] = cv2.minEnclosingCircle(contours_poly[i])\n",
    "    \n",
    "\n",
    "    arr_centers = np.asarray(centers)\n",
    "    arr_radius  = np.asarray(radius)\n",
    "\n",
    "    centers_inds = np.argsort(arr_centers[:,0])\n",
    "    sorted_centers = arr_centers[centers_inds[::]]\n",
    "    sorted_radius = arr_radius[centers_inds[::]]\n",
    "    \"\"\"\n",
    "    print(\"before:\", arr_centers)\n",
    "    print(arr_radius)\n",
    "    print(\"after:\", sorted_centers)\n",
    "    print(sorted_radius)\n",
    "    \"\"\"\n",
    "\n",
    "    new_centers = [sorted_centers[i] for i in range(len(sorted_centers)) if sorted_radius[i]>1 and sorted_radius[i]<7]\n",
    "    new_radius  = [sorted_radius[i] for i in range(len(sorted_radius)) if sorted_radius[i]>1 and sorted_radius[i]<7] \n",
    "    \n",
    "    \"\"\"\n",
    "    for i, x in enumerate(new_centers):\n",
    "      print(\"new centers\", x,\"new radius\", new_radius[i])\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    print(boundRect)\n",
    "    \"\"\"\n",
    "\n",
    "    drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(len(centers)):\n",
    "      color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "      cv2.circle(drawing, (int(centers[i][0]), int(centers[i][1])), int(radius[i]), color, 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(new_centers)):\n",
    "        color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "        cv2.circle(drawing, (int(new_centers[i][0]), int(new_centers[i][1])), int(new_radius[i]), color, 2)\n",
    "    \n",
    "    \"\"\"\n",
    "    displayGreyImage(drawing, \"contours\")\n",
    "    \"\"\"\n",
    "    \n",
    "    boxes = []\n",
    "    scores = []\n",
    "    boxes_tensor = torch.empty(size=(len(new_centers), 4))\n",
    "    scores_tensor = torch.empty(len(new_centers))\n",
    "    for i, x in enumerate(new_centers):\n",
    "        #print(int(x[0]-new_radius[i]))\n",
    "        bottom = np.floor(x[1]-new_radius[i]).astype(int)\n",
    "        top = np.ceil(x[1]+new_radius[i]).astype(int)\n",
    "        left = np.floor(x[0]-new_radius[i]).astype(int)\n",
    "        right = np.ceil(x[0]+new_radius[i]).astype(int)\n",
    "        \n",
    "        \"\"\"\n",
    "        print(f'bottom: {bottom} top: {top} left: {left} right: {right}')\n",
    "        \"\"\"\n",
    "\n",
    "        box = src_gray[bottom:top, left:right]\n",
    "        score = box.sum()\n",
    "        scores.append(score)\n",
    "\n",
    "        #displayGreyImage(box, i)\n",
    "        boxes.append(box)\n",
    "        \"\"\"\n",
    "        displayGreyImage(boxes[i], i)\n",
    "        \"\"\"\n",
    "        #box_tensor = torch.tensor([bottom, left, top, right])\n",
    "        #boxes_tensor = torch.cat([box_tensor],0)\n",
    "        boxes_tensor[i] = torch.tensor([left, bottom, right, top])\n",
    "        scores_tensor[i] = torch.tensor([score], dtype=torch.float32)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    print(f\"boxes:{boxes_tensor} scores: {scores_tensor}\")\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    max_boxes_ind = nms(boxes = boxes_tensor, scores = scores_tensor, iou_threshold=0.1)\n",
    "    \n",
    "    \"\"\"\n",
    "    print(max_boxes_ind)\n",
    "    \"\"\"\n",
    "    \n",
    "    #cv2_imshow(drawing)\n",
    "    \n",
    "    j_list = np.asarray(new_centers)\n",
    "    \"\"\"\n",
    "    print(j_list[:,0])\n",
    "    \"\"\"\n",
    "    j_list = np.asarray(j_list[:,0])\n",
    "    j_list = np.sort(j_list)\n",
    "    \"\"\"\n",
    "    print(\"jlist\", j_list)\n",
    "    #print(j_list[1]-j_list[0])\n",
    "    \"\"\"\n",
    "\n",
    "    # create a list of the diffirence in centers between consecutive values\n",
    "    gaps = [y - x for x, y in zip(j_list[:-1], j_list[1:])]\n",
    "    \"\"\"\n",
    "    print(gaps)\n",
    "    \"\"\"\n",
    "    \n",
    "    # have python calculate the standard deviation for the gaps\n",
    "    #sd = stdev(gaps)\n",
    "    \"\"\"\n",
    "    print(sd)\n",
    "    \"\"\"\n",
    "    # create a list of lists, put the first value of the source data in the first\n",
    "    lists = [[j_list[0]]]\n",
    "    \"\"\"\n",
    "    print(lists)\n",
    "    \"\"\"\n",
    "    radius_lists = [[new_radius[0]]]\n",
    "    mean_radius = np.median(new_radius)\n",
    "    #print(mean_radius)\n",
    "    for i, x in enumerate(j_list[1:]):\n",
    "        \"\"\"\n",
    "        print(x- lists[-1][-1])\n",
    "        print(new_radius[i])\n",
    "        \n",
    "        print(new_radius[i+1])\n",
    "        print(x-new_radius[i] - (lists[-1][-1]+new_radius[i-1]))\n",
    "        \"\"\"\n",
    "        # if the gap from the current item to the previous is more than 1 SD\n",
    "        # Note: the previous item is the last item in the last list\n",
    "        # Note: the '> 1' is the part you'd modify to make it stricter or more relaxed\n",
    "        if np.abs(x - (lists[-1][-1])) > 6: #radius[i] (new_radius[i]+new_radius[i+1])*2/3\n",
    "            lists.append([])\n",
    "            radius_lists.append([])\n",
    "        lists[-1].append(x)\n",
    "        radius_lists[-1].append(new_radius[i])\n",
    "    \"\"\"\n",
    "    print(lists)\n",
    "    print(radius_lists)\n",
    "    \"\"\"\n",
    "    digit_centers = np.asarray([np.mean(lists[i]) for i in range(len(lists))]).astype(int)\n",
    "    digit_radius = np.asarray([np.max(radius_lists[i]) for i in range(len(radius_lists))]).astype(int)\n",
    "\n",
    "    final_boxes = create_boxes_hacks(src, digit_centers)\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(len(final_boxes)):\n",
    "        displayGreyImage(final_boxes[i],\"\")\n",
    "    \"\"\"\n",
    "    \n",
    "    n_digits = len(final_boxes)\n",
    "\n",
    "    \"\"\"\n",
    "    print(digit_centers, digit_radius)\n",
    "    print(digit_centers)\n",
    "    print(len(digit_centers))\n",
    "    \"\"\"\n",
    "    return final_boxes, n_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect at index: 2903\n",
      "incorrect at index: 4555\n",
      "incorrect at index: 7230\n",
      "incorrect at index: 7472\n",
      "incorrect at index: 12016\n",
      "incorrect at index: 12127\n",
      "incorrect at index: 13485\n",
      "incorrect at index: 16017\n",
      "incorrect at index: 18127\n",
      "incorrect at index: 19418\n",
      "incorrect at index: 19580\n",
      "incorrect at index: 19752\n",
      "incorrect at index: 20317\n",
      "incorrect at index: 20829\n",
      "incorrect at index: 24262\n",
      "incorrect at index: 25284\n",
      "incorrect at index: 28261\n",
      "incorrect at index: 32014\n",
      "incorrect at index: 32944\n",
      "incorrect at index: 32954\n",
      "incorrect at index: 33012\n",
      "incorrect at index: 38206\n",
      "incorrect at index: 48432\n",
      "incorrect at index: 50390\n",
      "incorrect at index: 51039\n",
      "total percentage incorrect: 0.044642857142857144 %\n"
     ]
    }
   ],
   "source": [
    "wrong = 0 \n",
    "wrong_arr = []\n",
    "wrong_arr_index = []\n",
    "correct = []\n",
    "\n",
    "for i, sample in enumerate(train_dataset):\n",
    "    snips, n_dig = thresh_callback(sample)\n",
    "    real_num_digits = 5 - list(train_labels[i]).count(10)\n",
    "\n",
    "    if(n_dig != real_num_digits):\n",
    "        print(\"incorrect at index:\", i)\n",
    "        wrong += 1\n",
    "        wrong_arr.append(snips)\n",
    "        wrong_arr_index.append(i)  \n",
    "\n",
    "print(\"total percentage incorrect:\", wrong / len(train_dataset) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "num_test_digits = 0\n",
    "\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    images, n_digits = thresh_callback(sample)\n",
    "   \n",
    "    num_test_digits += n_digits\n",
    "\n",
    "divs = []\n",
    "\n",
    "for div in range(1, 100):\n",
    "    if(num_test_digits % (div) == 0):\n",
    "        divs.append(div)\n",
    "\n",
    "batch_size = divs[-1]\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(input_array, label_array, batch_size):\n",
    "    batched = []\n",
    "    label_batched = []\n",
    "    \n",
    "    for i in range(np.floor(len(input_array)/batch_size).astype(int)):\n",
    "        batched.append(np.expand_dims((np.array(input_array[i*batch_size:i*batch_size+batch_size])).astype(np.single),axis=1))\n",
    "        label_batched.append(label_array[i*batch_size:i*batch_size+batch_size])\n",
    "        \n",
    "    return np.array(batched), label_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, h_layers):\n",
    "        self.num_layers = len(h_layers)\n",
    "        self.h_layers = h_layers      \n",
    "        self.convs = []\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(3 * 3 * 256, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN for hyper-parameter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-5f2ff565ea8f>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-5f2ff565ea8f>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    if !dont_run:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "training_dataset_batch, training_labels_batch = create_batches(xTrainingSet, yTrainingSet, batch_size)\n",
    "validation_dataset_batch, validation_labels_batch = create_batches(xValidationSet, yValidationSet, batch_size)\n",
    "\n",
    "# model hyper-parameters\n",
    "h_layers = ([batch_size, 64])\n",
    "max_iters = 30\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "dont_run = True\n",
    "# train neural network\n",
    "\n",
    "if not dont_run:\n",
    "    net = Net(h_layers)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    for epoch in range(max_iters):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(training_dataset_batch):\n",
    "            inputs = torch.from_numpy(data)\n",
    "            labels = training_labels_batch[i] \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, torch.from_numpy(np.array(labels).astype(np.longlong)))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 20 == 19:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # test validation set on model\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataset_batch):\n",
    "            images = torch.from_numpy(data)\n",
    "            labels = validation_labels_batch[i]\n",
    "            labels = torch.from_numpy(np.array(labels).astype(np.longlong))\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if (int(predicted[0]) != int(labels[0])):\n",
    "                None\n",
    "\n",
    "    print(f\"validation set accuracy ({total} samples): {(100 * correct / total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN to predict unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = xTrainingSet + xValidationSet\n",
    "full_labels = yTrainingSet + yValidationSet\n",
    "\n",
    "full_dataset_batch, full_labels_batch = create_batches(full_dataset, full_labels, batch_size)\n",
    "\n",
    "net = Net(h_layers)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "for epoch in range(max_iters):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(full_dataset_batch):\n",
    "        inputs = torch.from_numpy(data)\n",
    "        labels = full_labels_batch[i] \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, torch.from_numpy(np.array(labels).astype(np.longlong)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 20 == 19:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated_digits = []\n",
    "\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    digits = []\n",
    "    \n",
    "    digits, n_digits = thresh_callback(sample)\n",
    "        \n",
    "    separated_digits.append(digits)\n",
    "    \n",
    "results = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    results.append([])\n",
    "\n",
    "row = 0\n",
    "col = 0\n",
    "    \n",
    "for i in range(int(num_test_digits / batch_size)):\n",
    "    batch = []\n",
    "    source = []\n",
    "    count = 0\n",
    "    \n",
    "    while count < batch_size:\n",
    "        batch.append(separated_digits[row][col])\n",
    "        source.append((row, col))\n",
    "        \n",
    "        if(col < len(separated_digits[row]) - 1):\n",
    "            col += 1\n",
    "        else:\n",
    "            row += 1\n",
    "            col = 0\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    batch = np.expand_dims(np.asarray(batch).astype(np.single), axis=1) \n",
    "    batch = torch.from_numpy(batch)\n",
    "    \n",
    "    output = net(batch)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    for j, pred in enumerate(predicted):\n",
    "        coord = source[j]\n",
    "        results[coord[0]].append(pred.item())\n",
    "        \n",
    "for r in results:\n",
    "    pad = 5 - len(r)\n",
    "    \n",
    "    for i in range(pad):\n",
    "        r.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(test_dataset):\n",
    "    displayGreyWindows(sample, \"\")\n",
    "    print(results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(str(results[0]))\n",
    "\n",
    "Id = []\n",
    "label = []\n",
    "for i, x in enumerate(results):\n",
    "    Id.append(i)\n",
    "    string = ''.join([str(elem) for elem in x])\n",
    "    label.append(string)\n",
    "\"\"\"\n",
    "print(Id[0],label[0])\n",
    "print(df[\"Label\"])\n",
    "\"\"\"\n",
    "data={\"Label\":label}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('sample.csv', index_label = \"Id\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
